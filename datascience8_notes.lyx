#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Practical machine learning - Notes
\end_layout

\begin_layout Author
Tanner Prestegard
\end_layout

\begin_layout Date
Course taken from 9/7/2015 - 10/4/2015
\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Subsection*

\series bold
Motivation and prerequisites
\end_layout

\begin_layout Itemize
Basic ideas behind machine learning/prediction
\end_layout

\begin_deeper
\begin_layout Itemize
Study design: training vs.
 test sets.
\end_layout

\begin_layout Itemize
Conceptual issues: out of sample error, ROC curves.
\end_layout

\begin_layout Itemize
Practical implementation: the caret package.
\end_layout

\end_deeper
\begin_layout Itemize
Who predicts things?
\end_layout

\begin_deeper
\begin_layout Itemize
Governments: pension payments.
\end_layout

\begin_layout Itemize
Google: whether you will click on an ad.
\end_layout

\begin_layout Itemize
Amazon: what movies you will watch.
\end_layout

\begin_layout Itemize
Insurance companies: what your risk of death is.
\end_layout

\begin_layout Itemize
Johns Hopkins: who will succeed in their programs.
\end_layout

\end_deeper
\begin_layout Subsection*
What is prediction?
\end_layout

\begin_layout Itemize
Components of a predictor:
\end_layout

\begin_deeper
\begin_layout Itemize
Question.
\end_layout

\begin_layout Itemize
Input data.
\end_layout

\begin_layout Itemize
Features.
\end_layout

\begin_layout Itemize
Algorithm.
\end_layout

\begin_layout Itemize
Parameters.
\end_layout

\begin_layout Itemize
Evaluation.
\end_layout

\end_deeper
\begin_layout Standard
Relative order of importance
\end_layout

\begin_layout Itemize
Defining the question is the most important step!
\end_layout

\begin_layout Itemize
Input data: garbage in = garbage out.
\end_layout

\begin_deeper
\begin_layout Itemize
May be easy: movie ratings -> new movie ratings.
\end_layout

\begin_layout Itemize
May be hard: gene expression data -> disease.
\end_layout

\begin_layout Itemize
Depends on how you define a 
\begin_inset Quotes eld
\end_inset

good prediction.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Often more data helps more than better models.
\end_layout

\begin_layout Itemize
Very important to collect the 
\begin_inset Quotes eld
\end_inset

right
\begin_inset Quotes erd
\end_inset

 data that is relevant to your question.
\end_layout

\end_deeper
\begin_layout Itemize
Features matter!
\end_layout

\begin_deeper
\begin_layout Itemize
Properties of good features:
\end_layout

\begin_deeper
\begin_layout Itemize
Lead to data compression.
\end_layout

\begin_layout Itemize
Retain relevant information.
\end_layout

\begin_layout Itemize
Are created based on expert application knowledge.
\end_layout

\end_deeper
\begin_layout Itemize
Common mistakes:
\end_layout

\begin_deeper
\begin_layout Itemize
Trying to automate feature selection.
\end_layout

\begin_layout Itemize
Not paying attention to data-specific quirks.
\end_layout

\begin_layout Itemize
Throwing away information unnecessarily.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Algorithms matter less than you'd think.
\end_layout

\begin_layout Itemize
Issues to consider: your method should be interpretable, simple, accurate,
 fast (to train and test), and scalable.
\end_layout

\begin_layout Itemize
Prediction is about accuracy tradeoffs:
\end_layout

\begin_deeper
\begin_layout Itemize
Interpretability versus accuracy.
\end_layout

\begin_layout Itemize
Speed versus accuracy.
\end_layout

\begin_layout Itemize
Simplicity versus accuracy.
\end_layout

\begin_layout Itemize
Scalability versus accuracy.
\end_layout

\end_deeper
\begin_layout Subsection*
In sample and out of sample errors
\end_layout

\begin_layout Itemize
In sample error: the error rate you get on the same data set that you used
 to build your predictor.
 Sometimes called resubstitution error.
 Usually slightly optimistic.
\end_layout

\begin_layout Itemize
Out of sample error: the error rate you get on a new data set.
 Sometimes calles generalization error.
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Out of sample error is what you really care about.
\end_layout

\begin_layout Itemize
In sample error < out of sample error, due to overfitting (matching your
 algorithm to the data you have).
\end_layout

\end_deeper
\begin_layout Itemize
Data have two parts: signal and noise.
\end_layout

\begin_deeper
\begin_layout Itemize
The goal of a predictor is to find signal.
\end_layout

\begin_layout Itemize
You can always design a perfect in-sample predictor, but you capture both
 signal and noise when you do that.
\end_layout

\begin_layout Itemize
This predictor won't perform as well on new samples (overfitting again).
\end_layout

\end_deeper
\begin_layout Subsection*
Prediction study design
\end_layout

\begin_layout Itemize
Define your error rate.
\end_layout

\begin_layout Itemize
Split data into: training, testing, and validation (optional) datasets.
\end_layout

\begin_layout Itemize
On the training set, pick features and use cross-validation.
\end_layout

\begin_layout Itemize
On the training set, pick a prediction function and use cross-validation.
\end_layout

\begin_layout Itemize
If no validation, apply the function once to the test set.
\end_layout

\begin_layout Itemize
If using validation, apply the function to the test set and refine, then
 apply once to the validation dataset.
\end_layout

\begin_layout Itemize
Avoid small sample sizes
\end_layout

\begin_deeper
\begin_layout Itemize
Example: predicting a binary outcome, like flipping a coin.
\end_layout

\begin_layout Itemize
Probability of perfect classification is approximately 
\begin_inset Formula $\left(1/2\right)^{\text{sample size}}$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $n=1$
\end_inset

: flipping a coin gives 50% chance of 100% accuracy.
\end_layout

\begin_layout Itemize
\begin_inset Formula $n=2$
\end_inset

: flipping a coin gives 25% chance of 100% accuracy.
\end_layout

\begin_layout Itemize
\begin_inset Formula $n=100$
\end_inset

: flipping a coin gives 0.1% chance of 100% accuracy.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Rules of thumb for prediction study design
\end_layout

\begin_deeper
\begin_layout Itemize
If you have a large sample size:
\end_layout

\begin_deeper
\begin_layout Itemize
60% training.
\end_layout

\begin_layout Itemize
20% test.
\end_layout

\begin_layout Itemize
20% validation.
\end_layout

\end_deeper
\begin_layout Itemize
If you have a medium sample size:
\end_layout

\begin_deeper
\begin_layout Itemize
60% training.
\end_layout

\begin_layout Itemize
40% testing.
\end_layout

\end_deeper
\begin_layout Itemize
If you have a small sample size:
\end_layout

\begin_deeper
\begin_layout Itemize
Do cross-validation.
\end_layout

\begin_layout Itemize
Report caveats of small sample size.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Some principles to remember:
\end_layout

\begin_deeper
\begin_layout Itemize
Set the test/validation set aside and don't look at it!
\end_layout

\begin_layout Itemize
In general, randomly sample the training and test datasets.
\end_layout

\begin_layout Itemize
Your datasets must reflect the structure of the problem: if predictions
 evolve with time, split the training/test by time chunks (called backtesting
 in finance).
\end_layout

\begin_layout Itemize
All subsets should reflect as much diversity as possible.
\end_layout

\begin_deeper
\begin_layout Itemize
Random assignment does this.
\end_layout

\begin_layout Itemize
You can also try to balance by features, but this is tricky.
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
Types of errors
\end_layout

\begin_layout Itemize
Positive = identified, negative = rejected.
\end_layout

\begin_deeper
\begin_layout Itemize
True positive (TP): correctly identified signal.
\end_layout

\begin_layout Itemize
False positive (FP): incorrectly identified noise as signal.
\end_layout

\begin_layout Itemize
True negative (TN): correctly rejected noise.
\end_layout

\begin_layout Itemize
False negative (FN): incorrectly rejected signal as noise.
\end_layout

\begin_layout Itemize
Sensitivity: Pr(positive test | sick person) = TP / (TP+FN)
\end_layout

\begin_layout Itemize
Specificity: Pr(negative test | healthy person) = TN / (FP + TN)
\end_layout

\begin_layout Itemize
Positive predictive value: Pr(sick person | positive test) = TP / (TP +
 FP)
\end_layout

\begin_layout Itemize
Negative predictive value: Pr(healthy person | negative test) = TN / (FN
 + TN)
\end_layout

\begin_layout Itemize
Accuracy: Pr(correct outcome) = (TP + TN) / (TP + FP + FN + TN)
\end_layout

\end_deeper
\begin_layout Itemize
For continuous data, there are a few ways to handle this.
\end_layout

\begin_deeper
\begin_layout Itemize
Mean squared error (MSE): 
\begin_inset Formula $MSE=\frac{1}{n}\sum_{i=1}^{n}\left(Prediction_{i}-Truth_{i}\right)^{2}$
\end_inset

 or root mean square error (RMSE): 
\begin_inset Formula $RMSE=\sqrt{MSE}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Itemize
Continuous data, sensitive to outliers (outliers may raise the mean significantl
y).
\end_layout

\end_deeper
\begin_layout Itemize
Median absolute deviation.
\end_layout

\begin_deeper
\begin_layout Itemize
Continuous data, often more robust.
\end_layout

\end_deeper
\begin_layout Itemize
Sensitivity: if you want few positives called negatives.
\end_layout

\begin_layout Itemize
Specificity: if you want few negatives called positives.
\end_layout

\begin_layout Itemize
Accuracy: weights false positives and negatives equally.
\end_layout

\begin_layout Itemize
Concordance.
\end_layout

\end_deeper
\begin_layout Subsection*
Receiver operating characteristic (ROC) curves
\end_layout

\begin_layout Itemize
Why a curve?
\end_layout

\begin_deeper
\begin_layout Itemize
In binary classification you are predicting one of two categories.
\end_layout

\begin_layout Itemize
But your predictions are ofen quantitative: probability of this or that.
\end_layout

\begin_layout Itemize
The 
\emph on
cutoff
\emph default
 you choose gives different results.
\end_layout

\end_deeper
\begin_layout Itemize
ROC curves:
\end_layout

\begin_deeper
\begin_layout Itemize
X-axis: 1 - specificity, or probability of being a false positive.
\end_layout

\begin_layout Itemize
Y-axis: probability of being a true positive.
\end_layout

\begin_layout Itemize
To compare different curves, you can calculate the total area under each
 curve (more area generally means a better predictor).
\end_layout

\begin_deeper
\begin_layout Itemize
Area under curve = 0.5 is equivalent to random guessing.
\end_layout

\begin_layout Itemize
Area under curve = 1 is a perfect classifier.
\end_layout

\begin_layout Itemize
In general, if your area under the curve is more than 0.8, that is considered
 
\begin_inset Quotes eld
\end_inset

good.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
Cross-validation
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Accuracy on the training set (resubstitution accuracy) is optimistic.
\end_layout

\begin_layout Itemize
A better estimate comes from an independent dataset (test set accuracy).
\end_layout

\begin_layout Itemize
But we can't use the test set when building the model or it becomes part
 of the training set.
\end_layout

\begin_layout Itemize
So we estimate the test set accuracy with the training set.
\end_layout

\end_deeper
\begin_layout Itemize
Cross-validation approach:
\end_layout

\begin_deeper
\begin_layout Itemize
Use the training set.
\end_layout

\begin_layout Itemize
Split it into training/test sets.
\end_layout

\begin_deeper
\begin_layout Itemize
Use random subsampling to do this.
\end_layout

\begin_layout Itemize
Can also do 
\begin_inset Quotes eld
\end_inset

K-fold
\begin_inset Quotes erd
\end_inset

 cross-validation.
\end_layout

\begin_layout Itemize
Another option: 
\begin_inset Quotes eld
\end_inset

leave one out
\begin_inset Quotes erd
\end_inset

.
 Use only one sample for test dataset and the rest for training; repeat
 with all samples.
\end_layout

\end_deeper
\begin_layout Itemize
Build a model on the training set.
\end_layout

\begin_layout Itemize
Evaluate on the test set.
\end_layout

\begin_layout Itemize
Repeat and average the estimated errors.
\end_layout

\end_deeper
\begin_layout Itemize
Useful for:
\end_layout

\begin_deeper
\begin_layout Itemize
Picking variables to include in the model.
\end_layout

\begin_layout Itemize
Picking the type of prediction function to use.
\end_layout

\begin_layout Itemize
Picking the parameters in the prediction function.
\end_layout

\begin_layout Itemize
Comparing different predictors.
\end_layout

\end_deeper
\begin_layout Itemize
Considerations:
\end_layout

\begin_deeper
\begin_layout Itemize
For time-series data, you must use chunks of data.
\end_layout

\begin_layout Itemize
For K-fold cross-validation.
\end_layout

\begin_deeper
\begin_layout Itemize
Larger K: less bias, more variance.
\end_layout

\begin_layout Itemize
Smaller K: more bias, less variance.
\end_layout

\end_deeper
\begin_layout Itemize
Random sampling must be done without replacement.
\end_layout

\begin_layout Itemize
Random sampling with replacement is called 
\emph on
bootstrapping.
\end_layout

\begin_deeper
\begin_layout Itemize
Underestimates the error.
\end_layout

\begin_layout Itemize
Can be corrected, but it's complicated (see 0.632 Bootstrap rule).
\end_layout

\end_deeper
\begin_layout Itemize
If you cross-validate to pick predictors, you must estimate errors on independen
t data.
\end_layout

\end_deeper
\begin_layout Subsection*
What data should you use?
\end_layout

\begin_layout Itemize
Key idea: to predict X, use data as closely related to X as you possibly
 can.
 (example: Moneyball; use player performance data to predict player performance)
\end_layout

\begin_layout Itemize
Using unrelated data is the most common mistake!
\end_layout

\begin_layout Subsection*
The caret package
\end_layout

\begin_layout Itemize
Short for 
\begin_inset Quotes eld
\end_inset

Classification And REgression Training)
\end_layout

\begin_layout Itemize
Streamlines the process for creating predictive models.
\end_layout

\begin_layout Itemize
Functionality
\end_layout

\begin_deeper
\begin_layout Itemize
Some pre-processing/cleaning: 
\family typewriter
preProcess
\end_layout

\begin_layout Itemize
Data splitting: 
\family typewriter
createDataPartition, createResample, createTimeSlices
\end_layout

\begin_layout Itemize
Training/testing functions: 
\family typewriter
train, predict
\end_layout

\begin_layout Itemize
Model comparison: 
\family typewriter
confusionMatrix
\end_layout

\end_deeper
\begin_layout Itemize
Machine learning algorithms in R
\end_layout

\begin_deeper
\begin_layout Itemize
Linear discriminant analysis
\end_layout

\begin_layout Itemize
Regression
\end_layout

\begin_layout Itemize
Naive Bayes
\end_layout

\begin_layout Itemize
Support vector machines
\end_layout

\begin_layout Itemize
Classification and regression trees
\end_layout

\begin_layout Itemize
Random forests
\end_layout

\begin_layout Itemize
Boosting
\end_layout

\begin_layout Itemize
Etc.
\end_layout

\end_deeper
\begin_layout Itemize
Example:
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(caret); library(kernlab); data(spam)
\end_layout

\begin_layout Plain Layout

## Divide data into training and test sets.
\end_layout

\begin_layout Plain Layout

## Split on data type, 75% training, 25% testing.
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
\end_layout

\begin_layout Plain Layout

training <- spam[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- spam[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Fit a model.
\end_layout

\begin_layout Plain Layout

set.seed(32343)
\end_layout

\begin_layout Plain Layout

modelFit <- train(type ~., data=training, method="glm")
\end_layout

\begin_layout Plain Layout

## Look at final model.
\end_layout

\begin_layout Plain Layout

modelFit$finalModel
\end_layout

\begin_layout Plain Layout

## Test on new samples.
\end_layout

\begin_layout Plain Layout

predictions <- predict(modelFit, newdata=testing)
\end_layout

\begin_layout Plain Layout

## Example: confusion matrix.
 Useful for getting several accuracy measures.
\end_layout

\begin_layout Plain Layout

confusionMatrix(predictions, testing$type)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Data slicing
\end_layout

\begin_layout Itemize
Example: K-fold
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

set.seed(32323)
\end_layout

\begin_layout Plain Layout

folds <- createFolds(y=spam$type, k=10, list=TRUE, returnTrain=TRUE)
\end_layout

\begin_layout Plain Layout

sapply(folds, length)
\end_layout

\begin_layout Plain Layout

## returnTrain=TRUE returns the training and testing sets,
\end_layout

\begin_layout Plain Layout

## returnTRAIN=FALSE returns only the testing set.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Example: resampling (with replacement)
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

set.seed(32323)
\end_layout

\begin_layout Plain Layout

folds <- createResample(y=spam$type, times=10, list=TRUE)
\end_layout

\begin_layout Plain Layout

sapply(folds, length)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Example: time slices
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

set.seed(32323)
\end_layout

\begin_layout Plain Layout

tme <- 1:1000
\end_layout

\begin_layout Plain Layout

folds <- createTimeSlices(y=tme, initialWindow=20, horizon=10)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Training options
\end_layout

\begin_layout Itemize
Use 
\family typewriter
args(train.default)
\family default
 to see all available options.
\end_layout

\begin_layout Itemize
Use 
\family typewriter
args(trainControl)
\family default
 to see other options for training setup.
\end_layout

\begin_layout Itemize
Continuous metric options:
\end_layout

\begin_deeper
\begin_layout Itemize
RMSE: root mean squared error.
\end_layout

\begin_layout Itemize
RSquared: 
\begin_inset Formula $R^{2}$
\end_inset

 from regression models.
\end_layout

\end_deeper
\begin_layout Itemize
Categorical outcomes:
\end_layout

\begin_deeper
\begin_layout Itemize
Accuracy: fraction correct.
\end_layout

\begin_layout Itemize
Kappa: a measure of concordance.
\end_layout

\end_deeper
\begin_layout Itemize

\family typewriter
trainControl
\family default
 resampling
\end_layout

\begin_deeper
\begin_layout Itemize
Method:
\end_layout

\begin_deeper
\begin_layout Itemize
boot: bootstrapping.
\end_layout

\begin_layout Itemize
boot632: bootstrapping with adjustment.
\end_layout

\begin_layout Itemize
cv: cross-validation.
\end_layout

\begin_layout Itemize
repeatedcv: repeated cross-validation.
\end_layout

\begin_layout Itemize
LOOCV: leave one out cross-validation.
\end_layout

\end_deeper
\begin_layout Itemize
Number:
\end_layout

\begin_deeper
\begin_layout Itemize
For boot/cross-validation.
\end_layout

\begin_layout Itemize
Number of subsamples to take.
\end_layout

\end_deeper
\begin_layout Itemize
Repeats:
\end_layout

\begin_deeper
\begin_layout Itemize
Number of times to repeate subsampling.
\end_layout

\begin_layout Itemize
If big, this can slow things down.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Setting the seed:
\end_layout

\begin_deeper
\begin_layout Itemize
It is often useful to set an overall seed.
\end_layout

\begin_layout Itemize
You can also set a seed for each resample.
\end_layout

\begin_layout Itemize
Seeding each resample is useful for parallel fits.
\end_layout

\end_deeper
\begin_layout Subsection*
Plotting predictors
\end_layout

\begin_layout Itemize
For this example, we will use the wages data (ISLR package).
\end_layout

\begin_layout Itemize
Feature plot (from caret package): 
\family typewriter
featurePlot(x=training[,c(
\begin_inset Quotes eld
\end_inset

age
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

education
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

jobclass
\begin_inset Quotes erd
\end_inset

)], y=training$wage, plot=
\begin_inset Quotes erd
\end_inset

pairs
\begin_inset Quotes erd
\end_inset

)
\end_layout

\begin_layout Itemize
Can use ggplot to plot by category (using color), plotting regression smoothers,
 etc.
\end_layout

\begin_layout Itemize
Can use 
\family typewriter
cut2
\family default
 (from Hmisc package) to make factors:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
cutWage <- cut2(training$wage, g=3) ## g=3 implies 3 groups
\end_layout

\end_deeper
\begin_layout Itemize
Another useful plot: box plots with points overlaid.
\end_layout

\begin_layout Itemize
Tables are useful.
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
prop.table()
\family default
 gives the proportion in each category.
\end_layout

\end_deeper
\begin_layout Itemize
Density plots are useful for continuous predictors.
\end_layout

\begin_deeper
\begin_layout Itemize
Example: 
\family typewriter
qplot(wage, color=education, data=training, geom=
\begin_inset Quotes erd
\end_inset

density
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_deeper
\begin_layout Itemize
Notes:
\end_layout

\begin_deeper
\begin_layout Itemize
Make your plots only with the training set!
\end_layout

\begin_layout Itemize
Things you should be looking for:
\end_layout

\begin_deeper
\begin_layout Itemize
Imbalance in outcomes/predictors.
\end_layout

\begin_layout Itemize
Outliers.
\end_layout

\begin_layout Itemize
Groups of points not explained by any of the predictors.
\end_layout

\begin_layout Itemize
Skewed variables.
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
Pre-processing
\end_layout

\begin_layout Itemize
Why preprocess?
\end_layout

\begin_deeper
\begin_layout Itemize
Sometimes certain predictors may have high variances, weird skews, etc.
\end_layout

\begin_layout Itemize
These features can cause problems for machine learning algorithms.
\end_layout

\begin_layout Itemize
You want to simplify things; the algorithm will likely produce better results
 this way.
\end_layout

\end_deeper
\begin_layout Itemize
Standardizing: 
\family typewriter
(x - mean(x))/sd(x)
\end_layout

\begin_deeper
\begin_layout Itemize
Produces variables with mean 0 and standard deviation 1.
\end_layout

\begin_layout Itemize
If we do this in the training, we have to do it to the test set, using the
 mean and SD of the 
\emph on
training
\emph default
 set!
\end_layout

\begin_layout Itemize

\family typewriter
preProcess
\family default
 function: 
\family typewriter
preObj <- preProcess(training[,-58], method=c(
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

scale
\begin_inset Quotes erd
\end_inset

))
\end_layout

\end_deeper
\begin_layout Itemize
Can pass the 
\family typewriter
preProcess
\family default
 command directly to the 
\family typewriter
train()
\family default
 function:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
modelFit <- train(type ~., data=training, preProcess=c(
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

scale
\begin_inset Quotes erd
\end_inset

), method=
\begin_inset Quotes erd
\end_inset

glm
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_deeper
\begin_layout Itemize
Box-Cox transforms: a set of transformations which take continuous data
 and try to make them look like normal data.
\end_layout

\begin_deeper
\begin_layout Itemize
Uses MLE methods.
\end_layout

\begin_layout Itemize
Can be used with 
\family typewriter
preProcess()
\family default
.
\end_layout

\end_deeper
\begin_layout Itemize
Imputing data: prediction algorithms will likely fail if there is missing
 data.
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
preObj <- preProcess(training[,-58], method=
\begin_inset Quotes erd
\end_inset

knnImpute
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_deeper
\begin_layout Itemize
Remember: the training and test datasets must be processed in the same way!
\end_layout

\begin_layout Itemize
Also: be careful when transforming factor variables!
\end_layout

\begin_layout Subsection*
Covariate creation
\end_layout

\begin_layout Itemize
Covariates: also known as predictors or features.
\end_layout

\begin_layout Itemize
Two levels of covariate creation:
\end_layout

\begin_deeper
\begin_layout Itemize
Level 1: from raw data to covariate.
\end_layout

\begin_deeper
\begin_layout Itemize
Depends heavily on the application.
\end_layout

\begin_layout Itemize
The balancing act is summarization vs.
 information loss.
\end_layout

\begin_layout Itemize
Examples:
\end_layout

\begin_deeper
\begin_layout Itemize
Text files: frequency of words, phrases, capital letters, etc.
\end_layout

\begin_layout Itemize
Images: edges, corners, blobs, ridges.
\end_layout

\begin_layout Itemize
Webpages: number and type of images, position of elements, colors, videos.
\end_layout

\begin_layout Itemize
People: height, weight, hair color, gender, country of origin.
\end_layout

\end_deeper
\begin_layout Itemize
The more knowledge of the system you have, the better job you will do.
\end_layout

\begin_layout Itemize
When in doubt, err on the side of more features.
\end_layout

\begin_layout Itemize
Can be automated, but use caution!
\end_layout

\end_deeper
\begin_layout Itemize
Level 2: transforming tidy covariates.
\end_layout

\begin_deeper
\begin_layout Itemize
More necessary for some methods (regression, svms, etc.) than for others
 (classification trees).
\end_layout

\begin_layout Itemize
Should be done only on the training set!
\end_layout

\begin_layout Itemize
The best approach is through exploratory analysis (plotting/tables).
\end_layout

\begin_layout Itemize
New covariates should be added to data frames.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Common covariates to add/dummy variables:
\end_layout

\begin_deeper
\begin_layout Itemize
Basic idea: convert factor variables to indicator variables.
 (quantitative information easier for algorithms to use than qualitative)
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

dummies <- dummyVar(wage ~ jobclass, data=training)
\end_layout

\begin_layout Plain Layout

head(predict(dummies, newdata=training)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Removing zero covariates: features with no variability (same for all cases)
 are not useful.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

nsv <- nearZeroVar(training, saveMetrics=TRUE)
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Spline basis - instead of fitting a linear prediction function, you can
 use a 
\begin_inset Quotes eld
\end_inset

curvy
\begin_inset Quotes erd
\end_inset

 line.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(splines)
\end_layout

\begin_layout Plain Layout

bsBasis <- bs(trainingage, df=3) ## degree 3 polynomial
\end_layout

\begin_layout Plain Layout

# Add model
\end_layout

\begin_layout Plain Layout

lm1 <- lm(wage ~ bsBasis, data=training)
\end_layout

\begin_layout Plain Layout

plot(training$age, training$wage, pch=19, cex=0.5)
\end_layout

\begin_layout Plain Layout

points(training$age, predict(lm1, newdata=training), col="red", pch=19,
 cex=0.5)
\end_layout

\begin_layout Plain Layout

## Apply to the test dataset
\end_layout

\begin_layout Plain Layout

predict(bsBasis, age=testing$age)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Notes and further reading
\end_layout

\begin_deeper
\begin_layout Itemize
Level 1 feature creation:
\end_layout

\begin_deeper
\begin_layout Itemize
Science is key.
 Google 
\begin_inset Quotes eld
\end_inset

feature extraction for [data type].
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Err on overcreation of features.
\end_layout

\begin_layout Itemize
In some applications (images, voices), automated feature creation is possible/ne
cessary.
\end_layout

\end_deeper
\begin_layout Itemize
Level 2 feature creation:
\end_layout

\begin_deeper
\begin_layout Itemize
The function 
\family typewriter
preProcess
\family default
 in caret will handle some preprocessing.
\end_layout

\begin_layout Itemize
Create new covariates if you think they will improve the fit.
\end_layout

\begin_layout Itemize
Use exploratory analysis on the training set for creating them.
\end_layout

\begin_layout Itemize
Be careful about overfitting.
\end_layout

\end_deeper
\begin_layout Itemize
If you want to fit spline models, use the 
\family typewriter
gam
\family default
 method in the caret package, which allows smoothing of multiple variables.
\end_layout

\end_deeper
\begin_layout Subsection*
Preprocessing with Principal Components Analysis (PCA)
\end_layout

\begin_layout Itemize
Useful when many predictors are correlated.
\end_layout

\begin_layout Itemize
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(caret); library(kernlab); data(spam)
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
\end_layout

\begin_layout Plain Layout

training <- spam[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- spam[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Calculate correlation between variables.
\end_layout

\begin_layout Plain Layout

M <- abs(cor(training[,-58]))
\end_layout

\begin_layout Plain Layout

diag(M) <- 0 ## Ignore self-correlations.
\end_layout

\begin_layout Plain Layout

which(M > 0.8, arr.ind=TRUE)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Basic PCA idea:
\end_layout

\begin_deeper
\begin_layout Itemize
We might not need every predictor.
\end_layout

\begin_layout Itemize
A weighted combination of correlated predictors might be better.
\end_layout

\begin_layout Itemize
We should pick this combination to capture the 
\begin_inset Quotes eld
\end_inset

most information
\begin_inset Quotes erd
\end_inset

 possible.
\end_layout

\begin_layout Itemize
Benefits: reduced number of predictors, reduced noise (due to averaging).
\end_layout

\end_deeper
\begin_layout Itemize
How to combine?
\end_layout

\begin_deeper
\begin_layout Itemize
You could rotate (i.e., add / subtract two variables).
\end_layout

\end_deeper
\begin_layout Itemize
Related problems:
\end_layout

\begin_deeper
\begin_layout Itemize
You have multivariate variables 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

 such that 
\begin_inset Formula $X_{1}=\left(X_{11},...,X_{1m}\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Find a new set of multivariate variables that are uncorrelated and explain
 as much variance as possible.
\end_layout

\begin_layout Itemize
If you put all the variables together in one matrix, find the best matrix
 created with fewer variables (lower rank) that explains the original ndata.
\end_layout

\begin_layout Itemize
The first goal is statistical and the second goal is data compression.
\end_layout

\end_deeper
\begin_layout Itemize
Related solutions:
\end_layout

\begin_deeper
\begin_layout Itemize
Singular value decomposition (SVD):
\end_layout

\begin_deeper
\begin_layout Itemize
If 
\begin_inset Formula $X$
\end_inset

 is a matrix with each variable in a column and each observation in a row,
 then the SVD is a matrix decomposition: 
\begin_inset Formula $X=UDV^{T}$
\end_inset

, where the columns of 
\bar under

\begin_inset Formula $U$
\end_inset


\bar default
 are orthogonal (left singular vectors), the columns of 
\begin_inset Formula $V$
\end_inset

 are orthogonal (right singular vectors), and 
\begin_inset Formula $D$
\end_inset

 is a diagonal matrix (singular values).
\end_layout

\end_deeper
\begin_layout Itemize
Principal components analysis (PCA):
\end_layout

\begin_deeper
\begin_layout Itemize
The principal components are equal to the right singular values if you first
 scale (subtract the mean, divide by the standard deviation) the variables.
\end_layout

\begin_layout Itemize
Example:
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

smallSpam <- spam[,c(34,32)]
\end_layout

\begin_layout Plain Layout

prComp <- prcomp(smallSpam)
\end_layout

\begin_layout Plain Layout

plot(prComp$x[,1],prComp$x[,2])
\end_layout

\begin_layout Plain Layout

## Look at rotation matrix
\end_layout

\begin_layout Plain Layout

prComp$rotation
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
PCA with caret package:
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

preProc <- preProcess(log10(spam[,-58]+1), method="pca", pcaComp=2)
\end_layout

\begin_layout Plain Layout

trainPC <- predict(preProc, log10(spam[,-58]+1))
\end_layout

\begin_layout Plain Layout

modelFit <- train(training$type ~ ., method="glm", data=trainPC)
\end_layout

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Most useful for linear-type models.
\end_layout

\begin_layout Itemize
Can make it harder to interpret predictors.
\end_layout

\begin_layout Itemize
Watch for outliers!
\end_layout

\begin_deeper
\begin_layout Itemize
Transform first (with logs/Box-Cox).
\end_layout

\begin_layout Itemize
Plot predictors to identify problems.
\end_layout

\end_deeper
\begin_layout Subsection*
Predicting with regression
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Fit a simple linear regression model.
\end_layout

\begin_layout Itemize
Plug in new covariates and multiply by the coefficients.
\end_layout

\begin_layout Itemize
Useful when the linear model is (nearly) correct.
\end_layout

\end_deeper
\begin_layout Itemize
Pros: easy to implement and interpret.
\end_layout

\begin_layout Itemize
Cons: often poor performance in nonlinear settings.
\end_layout

\begin_layout Itemize
Example: Old Faithful eruptions
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(caret); data(faithful); set.seed(333)
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list=FALSE)
\end_layout

\begin_layout Plain Layout

trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Fit a linear model
\end_layout

\begin_layout Plain Layout

lm1 <- lm(eruption ~ waiting, data=trainFaith
\end_layout

\begin_layout Plain Layout

## plot
\end_layout

\begin_layout Plain Layout

plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="Waiting
", ylab="Duration")
\end_layout

\begin_layout Plain Layout

lines(trainFaith$waiting, lm1$fitted, lwd=3)
\end_layout

\begin_layout Plain Layout

## Predict a new value
\end_layout

\begin_layout Plain Layout

coef(lm1)[1] + coef(lm1)[2]*80
\end_layout

\begin_layout Plain Layout

## Can do this as well
\end_layout

\begin_layout Plain Layout

newdata <- data.frame(waiting = 80)
\end_layout

\begin_layout Plain Layout

predict(lm1,newdata)
\end_layout

\begin_layout Plain Layout

## Plot predictions - training and test
\end_layout

\begin_layout Plain Layout

par(mfrow=c(1,2))
\end_layout

\begin_layout Plain Layout

plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",yl
ab="Duration")
\end_layout

\begin_layout Plain Layout

lines(trainFaith$waiting,predict(lm1),lwd=3)
\end_layout

\begin_layout Plain Layout

plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab
="Duration")
\end_layout

\begin_layout Plain Layout

lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
\end_layout

\begin_layout Plain Layout

## Get training set/test set errors
\end_layout

\begin_layout Plain Layout

## RMSE
\end_layout

\begin_layout Plain Layout

sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
\end_layout

\begin_layout Plain Layout

sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
\end_layout

\begin_layout Plain Layout

## Prediction intervals
\end_layout

\begin_layout Plain Layout

pred1 <- predict(lm1,newdata=testFaith, interval="prediction")
\end_layout

\begin_layout Plain Layout

ord <- order(testFaith$waiting)
\end_layout

\begin_layout Plain Layout

plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
\end_layout

\begin_layout Plain Layout

matlines(testFaith$waiting[ord],pred1[ord,],type="l",col=c(1,2,2),lty=c(1,1,1),l
wd=3)
\end_layout

\begin_layout Plain Layout

## Same process with caret
\end_layout

\begin_layout Plain Layout

modFit <- train(eruptions ~ waiting, data=trainFaith, method="lm")
\end_layout

\begin_layout Plain Layout

summary(modFit$finalModel)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Regression models with multiple covariates can be included.
\end_layout

\begin_layout Itemize
Often useful in combination with other models.
\end_layout

\begin_layout Subsection*
Predicting with regression - multiple covariates
\end_layout

\begin_layout Itemize
Important to decide which predictors are most useful
\end_layout

\begin_layout Itemize
Example: wage data
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(ISLR); library(ggplot2); library(caret);
\end_layout

\begin_layout Plain Layout

data(Wage); Wage <- subset(Wage, select=c(logwage))
\end_layout

\begin_layout Plain Layout

## Get training/test sets
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
\end_layout

\begin_layout Plain Layout

training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Feature plot
\end_layout

\begin_layout Plain Layout

featurePlot(x=training[,c("age","education","jobclass")], y=training$wage,
 plot="pairs")
\end_layout

\begin_layout Plain Layout

## Plot age vs.
 wage
\end_layout

\begin_layout Plain Layout

qplot(age, wage, data=training)
\end_layout

\begin_layout Plain Layout

## Plot age vs.
 wage, color by jobclass
\end_layout

\begin_layout Plain Layout

qplot(age, wage, color=jobclass, data=training)
\end_layout

\begin_layout Plain Layout

## Plot age vs.
 wage, color by education
\end_layout

\begin_layout Plain Layout

qplot(age, wage, color=education, data=training)
\end_layout

\begin_layout Plain Layout

## Fit a linear model with multiple variables
\end_layout

\begin_layout Plain Layout

modFit <- train(wage ~ age + jobclass + education, method="lm", data=training)
\end_layout

\begin_layout Plain Layout

finMod <- modFit$finalModel
\end_layout

\begin_layout Plain Layout

## Diagnostics
\end_layout

\begin_layout Plain Layout

plot(finMod, 1, pch=19, cex=0.5, col="#00000010")
\end_layout

\begin_layout Plain Layout

## Color by variables not used in the model
\end_layout

\begin_layout Plain Layout

qplot(finMod$fitted, finMod$residuals, color=race, data=training)
\end_layout

\begin_layout Plain Layout

## Plot by index
\end_layout

\begin_layout Plain Layout

plot(finMod$residuals, pch=19)
\end_layout

\begin_layout Plain Layout

## Predicted vs.
 truth in test set
\end_layout

\begin_layout Plain Layout

pred <- predict(modFit, testing)
\end_layout

\begin_layout Plain Layout

qplot(wage, pred, color=year, data=testing)
\end_layout

\begin_layout Plain Layout

## If you want to use all covariates
\end_layout

\begin_layout Plain Layout

modFitAll <- train(wage ~ ., data=training, method="lm")
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Often useful in combination with other models.
\end_layout

\end_body
\end_document

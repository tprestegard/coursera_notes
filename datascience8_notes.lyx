#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Practical machine learning - Notes
\end_layout

\begin_layout Author
Tanner Prestegard
\end_layout

\begin_layout Date
Course taken from 9/7/2015 - 10/4/2015
\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Subsection*

\series bold
Motivation and prerequisites
\end_layout

\begin_layout Itemize
Basic ideas behind machine learning/prediction
\end_layout

\begin_deeper
\begin_layout Itemize
Study design: training vs.
 test sets.
\end_layout

\begin_layout Itemize
Conceptual issues: out of sample error, ROC curves.
\end_layout

\begin_layout Itemize
Practical implementation: the caret package.
\end_layout

\end_deeper
\begin_layout Itemize
Who predicts things?
\end_layout

\begin_deeper
\begin_layout Itemize
Governments: pension payments.
\end_layout

\begin_layout Itemize
Google: whether you will click on an ad.
\end_layout

\begin_layout Itemize
Amazon: what movies you will watch.
\end_layout

\begin_layout Itemize
Insurance companies: what your risk of death is.
\end_layout

\begin_layout Itemize
Johns Hopkins: who will succeed in their programs.
\end_layout

\end_deeper
\begin_layout Subsection*
What is prediction?
\end_layout

\begin_layout Itemize
Components of a predictor:
\end_layout

\begin_deeper
\begin_layout Itemize
Question.
\end_layout

\begin_layout Itemize
Input data.
\end_layout

\begin_layout Itemize
Features.
\end_layout

\begin_layout Itemize
Algorithm.
\end_layout

\begin_layout Itemize
Parameters.
\end_layout

\begin_layout Itemize
Evaluation.
\end_layout

\end_deeper
\begin_layout Standard
Relative order of importance
\end_layout

\begin_layout Itemize
Defining the question is the most important step!
\end_layout

\begin_layout Itemize
Input data: garbage in = garbage out.
\end_layout

\begin_deeper
\begin_layout Itemize
May be easy: movie ratings -> new movie ratings.
\end_layout

\begin_layout Itemize
May be hard: gene expression data -> disease.
\end_layout

\begin_layout Itemize
Depends on how you define a 
\begin_inset Quotes eld
\end_inset

good prediction.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Often more data helps more than better models.
\end_layout

\begin_layout Itemize
Very important to collect the 
\begin_inset Quotes eld
\end_inset

right
\begin_inset Quotes erd
\end_inset

 data that is relevant to your question.
\end_layout

\end_deeper
\begin_layout Itemize
Features matter!
\end_layout

\begin_deeper
\begin_layout Itemize
Properties of good features:
\end_layout

\begin_deeper
\begin_layout Itemize
Lead to data compression.
\end_layout

\begin_layout Itemize
Retain relevant information.
\end_layout

\begin_layout Itemize
Are created based on expert application knowledge.
\end_layout

\end_deeper
\begin_layout Itemize
Common mistakes:
\end_layout

\begin_deeper
\begin_layout Itemize
Trying to automate feature selection.
\end_layout

\begin_layout Itemize
Not paying attention to data-specific quirks.
\end_layout

\begin_layout Itemize
Throwing away information unnecessarily.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Algorithms matter less than you'd think.
\end_layout

\begin_layout Itemize
Issues to consider: your method should be interpretable, simple, accurate,
 fast (to train and test), and scalable.
\end_layout

\begin_layout Itemize
Prediction is about accuracy tradeoffs:
\end_layout

\begin_deeper
\begin_layout Itemize
Interpretability versus accuracy.
\end_layout

\begin_layout Itemize
Speed versus accuracy.
\end_layout

\begin_layout Itemize
Simplicity versus accuracy.
\end_layout

\begin_layout Itemize
Scalability versus accuracy.
\end_layout

\end_deeper
\begin_layout Subsection*
In sample and out of sample errors
\end_layout

\begin_layout Itemize
In sample error: the error rate you get on the same data set that you used
 to build your predictor.
 Sometimes called resubstitution error.
 Usually slightly optimistic.
\end_layout

\begin_layout Itemize
Out of sample error: the error rate you get on a new data set.
 Sometimes calles generalization error.
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Out of sample error is what you really care about.
\end_layout

\begin_layout Itemize
In sample error < out of sample error, due to overfitting (matching your
 algorithm to the data you have).
\end_layout

\end_deeper
\begin_layout Itemize
Data have two parts: signal and noise.
\end_layout

\begin_deeper
\begin_layout Itemize
The goal of a predictor is to find signal.
\end_layout

\begin_layout Itemize
You can always design a perfect in-sample predictor, but you capture both
 signal and noise when you do that.
\end_layout

\begin_layout Itemize
This predictor won't perform as well on new samples (overfitting again).
\end_layout

\end_deeper
\begin_layout Subsection*
Prediction study design
\end_layout

\begin_layout Itemize
Define your error rate.
\end_layout

\begin_layout Itemize
Split data into: training, testing, and validation (optional) datasets.
\end_layout

\begin_layout Itemize
On the training set, pick features and use cross-validation.
\end_layout

\begin_layout Itemize
On the training set, pick a prediction function and use cross-validation.
\end_layout

\begin_layout Itemize
If no validation, apply the function once to the test set.
\end_layout

\begin_layout Itemize
If using validation, apply the function to the test set and refine, then
 apply once to the validation dataset.
\end_layout

\begin_layout Itemize
Avoid small sample sizes
\end_layout

\begin_deeper
\begin_layout Itemize
Example: predicting a binary outcome, like flipping a coin.
\end_layout

\begin_layout Itemize
Probability of perfect classification is approximately 
\begin_inset Formula $\left(1/2\right)^{\text{sample size}}$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $n=1$
\end_inset

: flipping a coin gives 50% chance of 100% accuracy.
\end_layout

\begin_layout Itemize
\begin_inset Formula $n=2$
\end_inset

: flipping a coin gives 25% chance of 100% accuracy.
\end_layout

\begin_layout Itemize
\begin_inset Formula $n=100$
\end_inset

: flipping a coin gives 0.1% chance of 100% accuracy.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Rules of thumb for prediction study design
\end_layout

\begin_deeper
\begin_layout Itemize
If you have a large sample size:
\end_layout

\begin_deeper
\begin_layout Itemize
60% training.
\end_layout

\begin_layout Itemize
20% test.
\end_layout

\begin_layout Itemize
20% validation.
\end_layout

\end_deeper
\begin_layout Itemize
If you have a medium sample size:
\end_layout

\begin_deeper
\begin_layout Itemize
60% training.
\end_layout

\begin_layout Itemize
40% testing.
\end_layout

\end_deeper
\begin_layout Itemize
If you have a small sample size:
\end_layout

\begin_deeper
\begin_layout Itemize
Do cross-validation.
\end_layout

\begin_layout Itemize
Report caveats of small sample size.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Some principles to remember:
\end_layout

\begin_deeper
\begin_layout Itemize
Set the test/validation set aside and don't look at it!
\end_layout

\begin_layout Itemize
In general, randomly sample the training and test datasets.
\end_layout

\begin_layout Itemize
Your datasets must reflect the structure of the problem: if predictions
 evolve with time, split the training/test by time chunks (called backtesting
 in finance).
\end_layout

\begin_layout Itemize
All subsets should reflect as much diversity as possible.
\end_layout

\begin_deeper
\begin_layout Itemize
Random assignment does this.
\end_layout

\begin_layout Itemize
You can also try to balance by features, but this is tricky.
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
Types of errors
\end_layout

\begin_layout Itemize
Positive = identified, negative = rejected.
\end_layout

\begin_deeper
\begin_layout Itemize
True positive (TP): correctly identified signal.
\end_layout

\begin_layout Itemize
False positive (FP): incorrectly identified noise as signal.
\end_layout

\begin_layout Itemize
True negative (TN): correctly rejected noise.
\end_layout

\begin_layout Itemize
False negative (FN): incorrectly rejected signal as noise.
\end_layout

\begin_layout Itemize
Sensitivity: Pr(positive test | sick person) = TP / (TP+FN)
\end_layout

\begin_layout Itemize
Specificity: Pr(negative test | healthy person) = TN / (FP + TN)
\end_layout

\begin_layout Itemize
Positive predictive value: Pr(sick person | positive test) = TP / (TP +
 FP)
\end_layout

\begin_layout Itemize
Negative predictive value: Pr(healthy person | negative test) = TN / (FN
 + TN)
\end_layout

\begin_layout Itemize
Accuracy: Pr(correct outcome) = (TP + TN) / (TP + FP + FN + TN)
\end_layout

\end_deeper
\begin_layout Itemize
For continuous data, there are a few ways to handle this.
\end_layout

\begin_deeper
\begin_layout Itemize
Mean squared error (MSE): 
\begin_inset Formula $MSE=\frac{1}{n}\sum_{i=1}^{n}\left(Prediction_{i}-Truth_{i}\right)^{2}$
\end_inset

 or root mean square error (RMSE): 
\begin_inset Formula $RMSE=\sqrt{MSE}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Itemize
Continuous data, sensitive to outliers (outliers may raise the mean significantl
y).
\end_layout

\end_deeper
\begin_layout Itemize
Median absolute deviation.
\end_layout

\begin_deeper
\begin_layout Itemize
Continuous data, often more robust.
\end_layout

\end_deeper
\begin_layout Itemize
Sensitivity: if you want few positives called negatives.
\end_layout

\begin_layout Itemize
Specificity: if you want few negatives called positives.
\end_layout

\begin_layout Itemize
Accuracy: weights false positives and negatives equally.
\end_layout

\begin_layout Itemize
Concordance.
\end_layout

\end_deeper
\begin_layout Subsection*
Receiver operating characteristic (ROC) curves
\end_layout

\begin_layout Itemize
Why a curve?
\end_layout

\begin_deeper
\begin_layout Itemize
In binary classification you are predicting one of two categories.
\end_layout

\begin_layout Itemize
But your predictions are ofen quantitative: probability of this or that.
\end_layout

\begin_layout Itemize
The 
\emph on
cutoff
\emph default
 you choose gives different results.
\end_layout

\end_deeper
\begin_layout Itemize
ROC curves:
\end_layout

\begin_deeper
\begin_layout Itemize
X-axis: 1 - specificity, or probability of being a false positive.
\end_layout

\begin_layout Itemize
Y-axis: probability of being a true positive.
\end_layout

\begin_layout Itemize
To compare different curves, you can calculate the total area under each
 curve (more area generally means a better predictor).
\end_layout

\begin_deeper
\begin_layout Itemize
Area under curve = 0.5 is equivalent to random guessing.
\end_layout

\begin_layout Itemize
Area under curve = 1 is a perfect classifier.
\end_layout

\begin_layout Itemize
In general, if your area under the curve is more than 0.8, that is considered
 
\begin_inset Quotes eld
\end_inset

good.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
Cross-validation
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Accuracy on the training set (resubstitution accuracy) is optimistic.
\end_layout

\begin_layout Itemize
A better estimate comes from an independent dataset (test set accuracy).
\end_layout

\begin_layout Itemize
But we can't use the test set when building the model or it becomes part
 of the training set.
\end_layout

\begin_layout Itemize
So we estimate the test set accuracy with the training set.
\end_layout

\end_deeper
\begin_layout Itemize
Cross-validation approach:
\end_layout

\begin_deeper
\begin_layout Itemize
Use the training set.
\end_layout

\begin_layout Itemize
Split it into training/test sets.
\end_layout

\begin_deeper
\begin_layout Itemize
Use random subsampling to do this.
\end_layout

\begin_layout Itemize
Can also do 
\begin_inset Quotes eld
\end_inset

K-fold
\begin_inset Quotes erd
\end_inset

 cross-validation.
\end_layout

\begin_layout Itemize
Another option: 
\begin_inset Quotes eld
\end_inset

leave one out
\begin_inset Quotes erd
\end_inset

.
 Use only one sample for test dataset and the rest for training; repeat
 with all samples.
\end_layout

\end_deeper
\begin_layout Itemize
Build a model on the training set.
\end_layout

\begin_layout Itemize
Evaluate on the test set.
\end_layout

\begin_layout Itemize
Repeat and average the estimated errors.
\end_layout

\end_deeper
\begin_layout Itemize
Useful for:
\end_layout

\begin_deeper
\begin_layout Itemize
Picking variables to include in the model.
\end_layout

\begin_layout Itemize
Picking the type of prediction function to use.
\end_layout

\begin_layout Itemize
Picking the parameters in the prediction function.
\end_layout

\begin_layout Itemize
Comparing different predictors.
\end_layout

\end_deeper
\begin_layout Itemize
Considerations:
\end_layout

\begin_deeper
\begin_layout Itemize
For time-series data, you must use chunks of data.
\end_layout

\begin_layout Itemize
For K-fold cross-validation.
\end_layout

\begin_deeper
\begin_layout Itemize
Larger K: less bias, more variance.
\end_layout

\begin_layout Itemize
Smaller K: more bias, less variance.
\end_layout

\end_deeper
\begin_layout Itemize
Random sampling must be done without replacement.
\end_layout

\begin_layout Itemize
Random sampling with replacement is called 
\emph on
bootstrapping.
\end_layout

\begin_deeper
\begin_layout Itemize
Underestimates the error.
\end_layout

\begin_layout Itemize
Can be corrected, but it's complicated (see 0.632 Bootstrap rule).
\end_layout

\end_deeper
\begin_layout Itemize
If you cross-validate to pick predictors, you must estimate errors on independen
t data.
\end_layout

\end_deeper
\begin_layout Subsection*
What data should you use?
\end_layout

\begin_layout Itemize
Key idea: to predict X, use data as closely related to X as you possibly
 can.
 (example: Moneyball; use player performance data to predict player performance)
\end_layout

\begin_layout Itemize
Using unrelated data is the most common mistake!
\end_layout

\begin_layout Subsection*
The caret package
\end_layout

\begin_layout Itemize
Short for 
\begin_inset Quotes eld
\end_inset

Classification And REgression Training)
\end_layout

\begin_layout Itemize
Streamlines the process for creating predictive models.
\end_layout

\begin_layout Itemize
Functionality
\end_layout

\begin_deeper
\begin_layout Itemize
Some pre-processing/cleaning: 
\family typewriter
preProcess
\end_layout

\begin_layout Itemize
Data splitting: 
\family typewriter
createDataPartition, createResample, createTimeSlices
\end_layout

\begin_layout Itemize
Training/testing functions: 
\family typewriter
train, predict
\end_layout

\begin_layout Itemize
Model comparison: 
\family typewriter
confusionMatrix
\end_layout

\end_deeper
\begin_layout Itemize
Machine learning algorithms in R
\end_layout

\begin_deeper
\begin_layout Itemize
Linear discriminant analysis
\end_layout

\begin_layout Itemize
Regression
\end_layout

\begin_layout Itemize
Naive Bayes
\end_layout

\begin_layout Itemize
Support vector machines
\end_layout

\begin_layout Itemize
Classification and regression trees
\end_layout

\begin_layout Itemize
Random forests
\end_layout

\begin_layout Itemize
Boosting
\end_layout

\begin_layout Itemize
Etc.
\end_layout

\end_deeper
\begin_layout Itemize
Example:
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(caret); library(kernlab); data(spam)
\end_layout

\begin_layout Plain Layout

## Divide data into training and test sets.
\end_layout

\begin_layout Plain Layout

## Split on data type, 75% training, 25% testing.
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
\end_layout

\begin_layout Plain Layout

training <- spam[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- spam[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Fit a model.
\end_layout

\begin_layout Plain Layout

set.seed(32343)
\end_layout

\begin_layout Plain Layout

modelFit <- train(type ~., data=training, method="glm")
\end_layout

\begin_layout Plain Layout

## Look at final model.
\end_layout

\begin_layout Plain Layout

modelFit$finalModel
\end_layout

\begin_layout Plain Layout

## Test on new samples.
\end_layout

\begin_layout Plain Layout

predictions <- predict(modelFit, newdata=testing)
\end_layout

\begin_layout Plain Layout

## Example: confusion matrix.
 Useful for getting several accuracy measures.
\end_layout

\begin_layout Plain Layout

confusionMatrix(predictions, testing$type)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Data slicing
\end_layout

\begin_layout Itemize
Example: K-fold
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

set.seed(32323)
\end_layout

\begin_layout Plain Layout

folds <- createFolds(y=spam$type, k=10, list=TRUE, returnTrain=TRUE)
\end_layout

\begin_layout Plain Layout

sapply(folds, length)
\end_layout

\begin_layout Plain Layout

## returnTrain=TRUE returns the training and testing sets,
\end_layout

\begin_layout Plain Layout

## returnTRAIN=FALSE returns only the testing set.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Example: resampling (with replacement)
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

set.seed(32323)
\end_layout

\begin_layout Plain Layout

folds <- createResample(y=spam$type, times=10, list=TRUE)
\end_layout

\begin_layout Plain Layout

sapply(folds, length)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Example: time slices
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

set.seed(32323)
\end_layout

\begin_layout Plain Layout

tme <- 1:1000
\end_layout

\begin_layout Plain Layout

folds <- createTimeSlices(y=tme, initialWindow=20, horizon=10)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Training options
\end_layout

\begin_layout Itemize
Use 
\family typewriter
args(train.default)
\family default
 to see all available options.
\end_layout

\begin_layout Itemize
Use 
\family typewriter
args(trainControl)
\family default
 to see other options for training setup.
\end_layout

\begin_layout Itemize
Continuous metric options:
\end_layout

\begin_deeper
\begin_layout Itemize
RMSE: root mean squared error.
\end_layout

\begin_layout Itemize
RSquared: 
\begin_inset Formula $R^{2}$
\end_inset

 from regression models.
\end_layout

\end_deeper
\begin_layout Itemize
Categorical outcomes:
\end_layout

\begin_deeper
\begin_layout Itemize
Accuracy: fraction correct.
\end_layout

\begin_layout Itemize
Kappa: a measure of concordance.
\end_layout

\end_deeper
\begin_layout Itemize

\family typewriter
trainControl
\family default
 resampling
\end_layout

\begin_deeper
\begin_layout Itemize
Method:
\end_layout

\begin_deeper
\begin_layout Itemize
boot: bootstrapping.
\end_layout

\begin_layout Itemize
boot632: bootstrapping with adjustment.
\end_layout

\begin_layout Itemize
cv: cross-validation.
\end_layout

\begin_layout Itemize
repeatedcv: repeated cross-validation.
\end_layout

\begin_layout Itemize
LOOCV: leave one out cross-validation.
\end_layout

\end_deeper
\begin_layout Itemize
Number:
\end_layout

\begin_deeper
\begin_layout Itemize
For boot/cross-validation.
\end_layout

\begin_layout Itemize
Number of subsamples to take.
\end_layout

\end_deeper
\begin_layout Itemize
Repeats:
\end_layout

\begin_deeper
\begin_layout Itemize
Number of times to repeate subsampling.
\end_layout

\begin_layout Itemize
If big, this can slow things down.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Setting the seed:
\end_layout

\begin_deeper
\begin_layout Itemize
It is often useful to set an overall seed.
\end_layout

\begin_layout Itemize
You can also set a seed for each resample.
\end_layout

\begin_layout Itemize
Seeding each resample is useful for parallel fits.
\end_layout

\end_deeper
\begin_layout Subsection*
Plotting predictors
\end_layout

\begin_layout Itemize
For this example, we will use the wages data (ISLR package).
\end_layout

\begin_layout Itemize
Feature plot (from caret package): 
\family typewriter
featurePlot(x=training[,c(
\begin_inset Quotes eld
\end_inset

age
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

education
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

jobclass
\begin_inset Quotes erd
\end_inset

)], y=training$wage, plot=
\begin_inset Quotes erd
\end_inset

pairs
\begin_inset Quotes erd
\end_inset

)
\end_layout

\begin_layout Itemize
Can use ggplot to plot by category (using color), plotting regression smoothers,
 etc.
\end_layout

\begin_layout Itemize
Can use 
\family typewriter
cut2
\family default
 (from Hmisc package) to make factors:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
cutWage <- cut2(training$wage, g=3) ## g=3 implies 3 groups
\end_layout

\end_deeper
\begin_layout Itemize
Another useful plot: box plots with points overlaid.
\end_layout

\begin_layout Itemize
Tables are useful.
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
prop.table()
\family default
 gives the proportion in each category.
\end_layout

\end_deeper
\begin_layout Itemize
Density plots are useful for continuous predictors.
\end_layout

\begin_deeper
\begin_layout Itemize
Example: 
\family typewriter
qplot(wage, color=education, data=training, geom=
\begin_inset Quotes erd
\end_inset

density
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_deeper
\begin_layout Itemize
Notes:
\end_layout

\begin_deeper
\begin_layout Itemize
Make your plots only with the training set!
\end_layout

\begin_layout Itemize
Things you should be looking for:
\end_layout

\begin_deeper
\begin_layout Itemize
Imbalance in outcomes/predictors.
\end_layout

\begin_layout Itemize
Outliers.
\end_layout

\begin_layout Itemize
Groups of points not explained by any of the predictors.
\end_layout

\begin_layout Itemize
Skewed variables.
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection*
Pre-processing
\end_layout

\begin_layout Itemize
Why preprocess?
\end_layout

\begin_deeper
\begin_layout Itemize
Sometimes certain predictors may have high variances, weird skews, etc.
\end_layout

\begin_layout Itemize
These features can cause problems for machine learning algorithms.
\end_layout

\begin_layout Itemize
You want to simplify things; the algorithm will likely produce better results
 this way.
\end_layout

\end_deeper
\begin_layout Itemize
Standardizing: 
\family typewriter
(x - mean(x))/sd(x)
\end_layout

\begin_deeper
\begin_layout Itemize
Produces variables with mean 0 and standard deviation 1.
\end_layout

\begin_layout Itemize
If we do this in the training, we have to do it to the test set, using the
 mean and SD of the 
\emph on
training
\emph default
 set!
\end_layout

\begin_layout Itemize

\family typewriter
preProcess
\family default
 function: 
\family typewriter
preObj <- preProcess(training[,-58], method=c(
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

scale
\begin_inset Quotes erd
\end_inset

))
\end_layout

\end_deeper
\begin_layout Itemize
Can pass the 
\family typewriter
preProcess
\family default
 command directly to the 
\family typewriter
train()
\family default
 function:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
modelFit <- train(type ~., data=training, preProcess=c(
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

,
\begin_inset Quotes erd
\end_inset

scale
\begin_inset Quotes erd
\end_inset

), method=
\begin_inset Quotes erd
\end_inset

glm
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_deeper
\begin_layout Itemize
Box-Cox transforms: a set of transformations which take continuous data
 and try to make them look like normal data.
\end_layout

\begin_deeper
\begin_layout Itemize
Uses MLE methods.
\end_layout

\begin_layout Itemize
Can be used with 
\family typewriter
preProcess()
\family default
.
\end_layout

\end_deeper
\begin_layout Itemize
Imputing data: prediction algorithms will likely fail if there is missing
 data.
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
preObj <- preProcess(training[,-58], method=
\begin_inset Quotes erd
\end_inset

knnImpute
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_deeper
\begin_layout Itemize
Remember: the training and test datasets must be processed in the same way!
\end_layout

\begin_layout Itemize
Also: be careful when transforming factor variables!
\end_layout

\begin_layout Subsection*
Covariate creation
\end_layout

\begin_layout Itemize
Covariates: also known as predictors or features.
\end_layout

\begin_layout Itemize
Two levels of covariate creation:
\end_layout

\begin_deeper
\begin_layout Itemize
Level 1: from raw data to covariate.
\end_layout

\begin_deeper
\begin_layout Itemize
Depends heavily on the application.
\end_layout

\begin_layout Itemize
The balancing act is summarization vs.
 information loss.
\end_layout

\begin_layout Itemize
Examples:
\end_layout

\begin_deeper
\begin_layout Itemize
Text files: frequency of words, phrases, capital letters, etc.
\end_layout

\begin_layout Itemize
Images: edges, corners, blobs, ridges.
\end_layout

\begin_layout Itemize
Webpages: number and type of images, position of elements, colors, videos.
\end_layout

\begin_layout Itemize
People: height, weight, hair color, gender, country of origin.
\end_layout

\end_deeper
\begin_layout Itemize
The more knowledge of the system you have, the better job you will do.
\end_layout

\begin_layout Itemize
When in doubt, err on the side of more features.
\end_layout

\begin_layout Itemize
Can be automated, but use caution!
\end_layout

\end_deeper
\begin_layout Itemize
Level 2: transforming tidy covariates.
\end_layout

\begin_deeper
\begin_layout Itemize
More necessary for some methods (regression, svms, etc.) than for others
 (classification trees).
\end_layout

\begin_layout Itemize
Should be done only on the training set!
\end_layout

\begin_layout Itemize
The best approach is through exploratory analysis (plotting/tables).
\end_layout

\begin_layout Itemize
New covariates should be added to data frames.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Common covariates to add/dummy variables:
\end_layout

\begin_deeper
\begin_layout Itemize
Basic idea: convert factor variables to indicator variables.
 (quantitative information easier for algorithms to use than qualitative)
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

dummies <- dummyVar(wage ~ jobclass, data=training)
\end_layout

\begin_layout Plain Layout

head(predict(dummies, newdata=training)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Removing zero covariates: features with no variability (same for all cases)
 are not useful.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

nsv <- nearZeroVar(training, saveMetrics=TRUE)
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Spline basis - instead of fitting a linear prediction function, you can
 use a 
\begin_inset Quotes eld
\end_inset

curvy
\begin_inset Quotes erd
\end_inset

 line.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(splines)
\end_layout

\begin_layout Plain Layout

bsBasis <- bs(trainingage, df=3) ## degree 3 polynomial
\end_layout

\begin_layout Plain Layout

# Add model
\end_layout

\begin_layout Plain Layout

lm1 <- lm(wage ~ bsBasis, data=training)
\end_layout

\begin_layout Plain Layout

plot(training$age, training$wage, pch=19, cex=0.5)
\end_layout

\begin_layout Plain Layout

points(training$age, predict(lm1, newdata=training), col="red", pch=19,
 cex=0.5)
\end_layout

\begin_layout Plain Layout

## Apply to the test dataset
\end_layout

\begin_layout Plain Layout

predict(bsBasis, age=testing$age)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Notes and further reading
\end_layout

\begin_deeper
\begin_layout Itemize
Level 1 feature creation:
\end_layout

\begin_deeper
\begin_layout Itemize
Science is key.
 Google 
\begin_inset Quotes eld
\end_inset

feature extraction for [data type].
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Err on overcreation of features.
\end_layout

\begin_layout Itemize
In some applications (images, voices), automated feature creation is possible/ne
cessary.
\end_layout

\end_deeper
\begin_layout Itemize
Level 2 feature creation:
\end_layout

\begin_deeper
\begin_layout Itemize
The function 
\family typewriter
preProcess
\family default
 in caret will handle some preprocessing.
\end_layout

\begin_layout Itemize
Create new covariates if you think they will improve the fit.
\end_layout

\begin_layout Itemize
Use exploratory analysis on the training set for creating them.
\end_layout

\begin_layout Itemize
Be careful about overfitting.
\end_layout

\end_deeper
\begin_layout Itemize
If you want to fit spline models, use the 
\family typewriter
gam
\family default
 method in the caret package, which allows smoothing of multiple variables.
\end_layout

\end_deeper
\begin_layout Subsection*
Preprocessing with Principal Components Analysis (PCA)
\end_layout

\begin_layout Itemize
Useful when many predictors are correlated.
\end_layout

\begin_layout Itemize
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(caret); library(kernlab); data(spam)
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
\end_layout

\begin_layout Plain Layout

training <- spam[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- spam[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Calculate correlation between variables.
\end_layout

\begin_layout Plain Layout

M <- abs(cor(training[,-58]))
\end_layout

\begin_layout Plain Layout

diag(M) <- 0 ## Ignore self-correlations.
\end_layout

\begin_layout Plain Layout

which(M > 0.8, arr.ind=TRUE)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Basic PCA idea:
\end_layout

\begin_deeper
\begin_layout Itemize
We might not need every predictor.
\end_layout

\begin_layout Itemize
A weighted combination of correlated predictors might be better.
\end_layout

\begin_layout Itemize
We should pick this combination to capture the 
\begin_inset Quotes eld
\end_inset

most information
\begin_inset Quotes erd
\end_inset

 possible.
\end_layout

\begin_layout Itemize
Benefits: reduced number of predictors, reduced noise (due to averaging).
\end_layout

\end_deeper
\begin_layout Itemize
How to combine?
\end_layout

\begin_deeper
\begin_layout Itemize
You could rotate (i.e., add / subtract two variables).
\end_layout

\end_deeper
\begin_layout Itemize
Related problems:
\end_layout

\begin_deeper
\begin_layout Itemize
You have multivariate variables 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

 such that 
\begin_inset Formula $X_{1}=\left(X_{11},...,X_{1m}\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Find a new set of multivariate variables that are uncorrelated and explain
 as much variance as possible.
\end_layout

\begin_layout Itemize
If you put all the variables together in one matrix, find the best matrix
 created with fewer variables (lower rank) that explains the original ndata.
\end_layout

\begin_layout Itemize
The first goal is statistical and the second goal is data compression.
\end_layout

\end_deeper
\begin_layout Itemize
Related solutions:
\end_layout

\begin_deeper
\begin_layout Itemize
Singular value decomposition (SVD):
\end_layout

\begin_deeper
\begin_layout Itemize
If 
\begin_inset Formula $X$
\end_inset

 is a matrix with each variable in a column and each observation in a row,
 then the SVD is a matrix decomposition: 
\begin_inset Formula $X=UDV^{T}$
\end_inset

, where the columns of 
\bar under

\begin_inset Formula $U$
\end_inset


\bar default
 are orthogonal (left singular vectors), the columns of 
\begin_inset Formula $V$
\end_inset

 are orthogonal (right singular vectors), and 
\begin_inset Formula $D$
\end_inset

 is a diagonal matrix (singular values).
\end_layout

\end_deeper
\begin_layout Itemize
Principal components analysis (PCA):
\end_layout

\begin_deeper
\begin_layout Itemize
The principal components are equal to the right singular values if you first
 scale (subtract the mean, divide by the standard deviation) the variables.
\end_layout

\begin_layout Itemize
Example:
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

smallSpam <- spam[,c(34,32)]
\end_layout

\begin_layout Plain Layout

prComp <- prcomp(smallSpam)
\end_layout

\begin_layout Plain Layout

plot(prComp$x[,1],prComp$x[,2])
\end_layout

\begin_layout Plain Layout

## Look at rotation matrix
\end_layout

\begin_layout Plain Layout

prComp$rotation
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
PCA with caret package:
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

preProc <- preProcess(log10(spam[,-58]+1), method="pca", pcaComp=2)
\end_layout

\begin_layout Plain Layout

trainPC <- predict(preProc, log10(spam[,-58]+1))
\end_layout

\begin_layout Plain Layout

modelFit <- train(training$type ~ ., method="glm", data=trainPC)
\end_layout

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Most useful for linear-type models.
\end_layout

\begin_layout Itemize
Can make it harder to interpret predictors.
\end_layout

\begin_layout Itemize
Watch for outliers!
\end_layout

\begin_deeper
\begin_layout Itemize
Transform first (with logs/Box-Cox).
\end_layout

\begin_layout Itemize
Plot predictors to identify problems.
\end_layout

\end_deeper
\begin_layout Subsection*
Predicting with regression
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Fit a simple linear regression model.
\end_layout

\begin_layout Itemize
Plug in new covariates and multiply by the coefficients.
\end_layout

\begin_layout Itemize
Useful when the linear model is (nearly) correct.
\end_layout

\end_deeper
\begin_layout Itemize
Pros: easy to implement and interpret.
\end_layout

\begin_layout Itemize
Cons: often poor performance in nonlinear settings.
\end_layout

\begin_layout Itemize
Example: Old Faithful eruptions
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(caret); data(faithful); set.seed(333)
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list=FALSE)
\end_layout

\begin_layout Plain Layout

trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Fit a linear model
\end_layout

\begin_layout Plain Layout

lm1 <- lm(eruption ~ waiting, data=trainFaith
\end_layout

\begin_layout Plain Layout

## plot
\end_layout

\begin_layout Plain Layout

plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="Waiting
", ylab="Duration")
\end_layout

\begin_layout Plain Layout

lines(trainFaith$waiting, lm1$fitted, lwd=3)
\end_layout

\begin_layout Plain Layout

## Predict a new value
\end_layout

\begin_layout Plain Layout

coef(lm1)[1] + coef(lm1)[2]*80
\end_layout

\begin_layout Plain Layout

## Can do this as well
\end_layout

\begin_layout Plain Layout

newdata <- data.frame(waiting = 80)
\end_layout

\begin_layout Plain Layout

predict(lm1,newdata)
\end_layout

\begin_layout Plain Layout

## Plot predictions - training and test
\end_layout

\begin_layout Plain Layout

par(mfrow=c(1,2))
\end_layout

\begin_layout Plain Layout

plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",yl
ab="Duration")
\end_layout

\begin_layout Plain Layout

lines(trainFaith$waiting,predict(lm1),lwd=3)
\end_layout

\begin_layout Plain Layout

plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab
="Duration")
\end_layout

\begin_layout Plain Layout

lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
\end_layout

\begin_layout Plain Layout

## Get training set/test set errors
\end_layout

\begin_layout Plain Layout

## RMSE
\end_layout

\begin_layout Plain Layout

sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
\end_layout

\begin_layout Plain Layout

sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
\end_layout

\begin_layout Plain Layout

## Prediction intervals
\end_layout

\begin_layout Plain Layout

pred1 <- predict(lm1,newdata=testFaith, interval="prediction")
\end_layout

\begin_layout Plain Layout

ord <- order(testFaith$waiting)
\end_layout

\begin_layout Plain Layout

plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
\end_layout

\begin_layout Plain Layout

matlines(testFaith$waiting[ord],pred1[ord,],type="l",col=c(1,2,2),lty=c(1,1,1),l
wd=3)
\end_layout

\begin_layout Plain Layout

## Same process with caret
\end_layout

\begin_layout Plain Layout

modFit <- train(eruptions ~ waiting, data=trainFaith, method="lm")
\end_layout

\begin_layout Plain Layout

summary(modFit$finalModel)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Regression models with multiple covariates can be included.
\end_layout

\begin_layout Itemize
Often useful in combination with other models.
\end_layout

\begin_layout Subsection*
Predicting with regression - multiple covariates
\end_layout

\begin_layout Itemize
Important to decide which predictors are most useful
\end_layout

\begin_layout Itemize
Example: wage data
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(ISLR); library(ggplot2); library(caret);
\end_layout

\begin_layout Plain Layout

data(Wage); Wage <- subset(Wage, select=c(logwage))
\end_layout

\begin_layout Plain Layout

## Get training/test sets
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
\end_layout

\begin_layout Plain Layout

training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Feature plot
\end_layout

\begin_layout Plain Layout

featurePlot(x=training[,c("age","education","jobclass")], y=training$wage,
 plot="pairs")
\end_layout

\begin_layout Plain Layout

## Plot age vs.
 wage
\end_layout

\begin_layout Plain Layout

qplot(age, wage, data=training)
\end_layout

\begin_layout Plain Layout

## Plot age vs.
 wage, color by jobclass
\end_layout

\begin_layout Plain Layout

qplot(age, wage, color=jobclass, data=training)
\end_layout

\begin_layout Plain Layout

## Plot age vs.
 wage, color by education
\end_layout

\begin_layout Plain Layout

qplot(age, wage, color=education, data=training)
\end_layout

\begin_layout Plain Layout

## Fit a linear model with multiple variables
\end_layout

\begin_layout Plain Layout

modFit <- train(wage ~ age + jobclass + education, method="lm", data=training)
\end_layout

\begin_layout Plain Layout

finMod <- modFit$finalModel
\end_layout

\begin_layout Plain Layout

## Diagnostics
\end_layout

\begin_layout Plain Layout

plot(finMod, 1, pch=19, cex=0.5, col="#00000010")
\end_layout

\begin_layout Plain Layout

## Color by variables not used in the model
\end_layout

\begin_layout Plain Layout

qplot(finMod$fitted, finMod$residuals, color=race, data=training)
\end_layout

\begin_layout Plain Layout

## Plot by index
\end_layout

\begin_layout Plain Layout

plot(finMod$residuals, pch=19)
\end_layout

\begin_layout Plain Layout

## Predicted vs.
 truth in test set
\end_layout

\begin_layout Plain Layout

pred <- predict(modFit, testing)
\end_layout

\begin_layout Plain Layout

qplot(wage, pred, color=year, data=testing)
\end_layout

\begin_layout Plain Layout

## If you want to use all covariates
\end_layout

\begin_layout Plain Layout

modFitAll <- train(wage ~ ., data=training, method="lm")
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Often useful in combination with other models.
\end_layout

\begin_layout Subsection*
Predicting with decision trees
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Iteratively split variables into groups.
\end_layout

\begin_layout Itemize
Evaluate homogeneity within each group.
\end_layout

\begin_layout Itemize
Split again if necessary.
\end_layout

\end_deeper
\begin_layout Itemize
Pros: easy to interpret, better performance in nonlinear settings.
\end_layout

\begin_layout Itemize
Cons: without pruning/cross-validation can lead to overfitting, harder to
 estimate uncertainty, results may be variable.
\end_layout

\begin_layout Itemize
Basic algorithm:
\end_layout

\begin_deeper
\begin_layout Itemize
Start with all variables in one group.
\end_layout

\begin_layout Itemize
Find the variable/split that best separates the outcomes.
\end_layout

\begin_layout Itemize
Divide the data into two groups (
\begin_inset Quotes eld
\end_inset

leaves
\begin_inset Quotes erd
\end_inset

) on that split/node.
\end_layout

\begin_layout Itemize
Within each split, find the best variable/split that separates the outcomes.
\end_layout

\begin_layout Itemize
Continue until the groups are too small or sufficiently pure to stop the
 algorithm.
\end_layout

\end_deeper
\begin_layout Itemize
Measures of impurity:
\end_layout

\begin_deeper
\begin_layout Itemize
In the 
\begin_inset Formula $m$
\end_inset

th leaf, there are 
\begin_inset Formula $N_{m}$
\end_inset

 total objects that we might consider.
 You can count the number of times that class 
\begin_inset Formula $k$
\end_inset

 appears in leaf 
\begin_inset Formula $m$
\end_inset

: 
\begin_inset Formula $p_{mk}=\frac{1}{N_{m}}\sum_{x_{i}\text{ in leaf }m}\mathbb{I}\left(y_{i}=k\right)$
\end_inset


\end_layout

\begin_layout Itemize
Misclassification error: 
\begin_inset Formula $1-p_{mk\left(m\right)}$
\end_inset

where 
\begin_inset Formula $k\left(m\right)$
\end_inset

 is the most common class.
\end_layout

\begin_deeper
\begin_layout Itemize
0 = perfect purity.
\end_layout

\begin_layout Itemize
0.5 = no purity (no homogeneity).
\end_layout

\end_deeper
\begin_layout Itemize
Gini index: 
\begin_inset Formula $1-\sum_{k=1}^{K}p_{mk}^{2}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
0 = perfect purity.
\end_layout

\begin_layout Itemize
0.5 = no purity.
\end_layout

\end_deeper
\begin_layout Itemize
Deviance (natural log)/information gain (log base 2): 
\begin_inset Formula $-\sum_{k=1}^{K}\log_{2}p_{mk}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
0 = perfect purity.
\end_layout

\begin_layout Itemize
1 = no purity.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Example: iris data
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

data(iris); library(ggplot2)
\end_layout

\begin_layout Plain Layout

## Trying to predict species
\end_layout

\begin_layout Plain Layout

table(iris$Species)
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=iris$Species, p=0.7, list=F)
\end_layout

\begin_layout Plain Layout

training <- iris[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- iris[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Exploratory plot
\end_layout

\begin_layout Plain Layout

qplot(Petal.Width, Sepal.Width, color=Species, data=training)
\end_layout

\begin_layout Plain Layout

## Fit a model with rpart (one package for classification trees)
\end_layout

\begin_layout Plain Layout

library(caret)
\end_layout

\begin_layout Plain Layout

modFit <- train(Species ~ ., method="rpart", data=training)
\end_layout

\begin_layout Plain Layout

print(modFit$finalModel)
\end_layout

\begin_layout Plain Layout

## Plot classification tree
\end_layout

\begin_layout Plain Layout

plot(modFit$finalModel, uniform=T, main="Classification Tree")
\end_layout

\begin_layout Plain Layout

text(modFit$finalModel, use.n=T, all=T, cex=0.8)
\end_layout

\begin_layout Plain Layout

## Another fancy plot
\end_layout

\begin_layout Plain Layout

library(rattle)
\end_layout

\begin_layout Plain Layout

fancyRpartPlot(modFit$finalModel)
\end_layout

\begin_layout Plain Layout

## Predict new values
\end_layout

\begin_layout Plain Layout

predict(modFit, newdata=testing)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Notes:
\end_layout

\begin_deeper
\begin_layout Itemize
Classification trees are non-linear models - they use interactions between
 variables.
\end_layout

\begin_layout Itemize
Data transformations may be less important.
\end_layout

\begin_layout Itemize
Trees can also be used for regression problems (continuous outcome).
\end_layout

\begin_layout Itemize
Multiple tree building options in R both in the caret package (party, rpart)
 and outside (tree).
\end_layout

\end_deeper
\begin_layout Subsection*
Bagging (bootstrap aggregating)
\end_layout

\begin_layout Itemize
When you fit complicated models, if you average them together, the resulting
 smoother fit gives a better balance between bias and variance in your fit.
\end_layout

\begin_layout Itemize
Basic idea:
\end_layout

\begin_deeper
\begin_layout Itemize
Resample cases (with replacement) and recalculate predictions.
\end_layout

\begin_layout Itemize
Average or majority vote.
\end_layout

\begin_layout Itemize
Notes:
\end_layout

\begin_deeper
\begin_layout Itemize
Similar bias compared to any individual model.
\end_layout

\begin_layout Itemize
Reduced variance.
\end_layout

\begin_layout Itemize
Most useful for non-linear functions.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Example: ozone data
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(ElemStatLearn); data(ozone, package="ElemStatLearn")
\end_layout

\begin_layout Plain Layout

ozone <- ozone[order(ozone$ozone)]
\end_layout

\begin_layout Plain Layout

head(ozone)
\end_layout

\begin_layout Plain Layout

## Idea is to predict temperature as a function of ozone.
\end_layout

\begin_layout Plain Layout

ll <- matrix(NA, nrow=10, ncol=155)
\end_layout

\begin_layout Plain Layout

for (i in 1:10) {
\end_layout

\begin_layout Plain Layout

	## Subsample and re-order.
\end_layout

\begin_layout Plain Layout

	ss <- sample(1:dim(ozone)[1], replace=T)
\end_layout

\begin_layout Plain Layout

	ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
\end_layout

\begin_layout Plain Layout

	## Fit a Loess curve, span = measure of fit smoothness.
\end_layout

\begin_layout Plain Layout

	loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
\end_layout

\begin_layout Plain Layout

	## Predict and store the results.
\end_layout

\begin_layout Plain Layout

	ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

## Plot
\end_layout

\begin_layout Plain Layout

plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5
\end_layout

\begin_layout Plain Layout

for (i in 1:10) {lines(1:155, ll[i,], col="gre", lwd=2)}
\end_layout

\begin_layout Plain Layout

lines(1:155, apply(ll,2,mean), col="red", lwd=2)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Bagging in caret: some models perform bagging for you, in the 
\family typewriter
train
\family default
 function, consider 
\family typewriter
method
\family default
 options.
\end_layout

\begin_deeper
\begin_layout Itemize
bagEarth
\end_layout

\begin_layout Itemize
treebag
\end_layout

\begin_layout Itemize
bagFDA
\end_layout

\begin_layout Itemize
Alternatively, you can bag any model you choose, using the 
\family typewriter
bag
\family default
 function.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

predictors <- data.frame(ozone=ozone$ozone)
\end_layout

\begin_layout Plain Layout

temperature <- ozone$temperature
\end_layout

\begin_layout Plain Layout

treebag <- bag(predictors, temperature, B=10,
\end_layout

\begin_layout Plain Layout

		       bagControl = bagControl(fit = ctreeBag$fit,
\end_layout

\begin_layout Plain Layout

									   predict = ctreeBag$pred,
\end_layout

\begin_layout Plain Layout

									   aggregate = ctreeBag$aggregate))
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Parts of bagging:
\end_layout

\begin_deeper
\begin_layout Itemize
Fit: takes in data frame and otucome that we passed and uses the 
\family typewriter
ctree
\family default
 function to train a conditional regression tree.
\end_layout

\begin_layout Itemize
Prediction: takes in the objects and a new dataset and gets a new prediction.
\end_layout

\begin_layout Itemize
Aggregation: takes in those values and combines them in some way.
\end_layout

\end_deeper
\begin_layout Itemize
Bagging is most useful for nonlinear models.
\end_layout

\begin_layout Itemize
Often used with trees, an extension is called 
\begin_inset Quotes eld
\end_inset

random forests.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Several models use bagging in caret's 
\family typewriter
train
\family default
 function.
\end_layout

\begin_layout Subsection*
Random forests
\end_layout

\begin_layout Itemize
Basic idea:
\end_layout

\begin_deeper
\begin_layout Itemize
Bootstrap samples; rebuild classification and regression trees for each
 set of samples.
\end_layout

\begin_layout Itemize
At each split, bootstrap variables - only a subset of variables is considered
 at each potential split..
\end_layout

\begin_layout Itemize
Grow multiple trees and vote.
\end_layout

\end_deeper
\begin_layout Itemize
Pros: accuracy.
\end_layout

\begin_layout Itemize
Cons: speed, interpretability, overfitting (very important to use cross-validati
on).
\end_layout

\begin_layout Itemize
Example: iris data.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

data(iris); library(ggplot2)
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=iris$species, p=0.7, list=F)
\end_layout

\begin_layout Plain Layout

training <- iris[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- iris[-inTrain,]
\end_layout

\begin_layout Plain Layout

library(caret)
\end_layout

\begin_layout Plain Layout

## Method rf is random forests.
\end_layout

\begin_layout Plain Layout

modFit <- train(Species ~ ., data=training, method="rf", prox=T)
\end_layout

\begin_layout Plain Layout

## Getting a single tree, k specifies which tree
\end_layout

\begin_layout Plain Layout

getTree(modFit$finalModel, k=2)
\end_layout

\begin_layout Plain Layout

## Class "centers"
\end_layout

\begin_layout Plain Layout

irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox
)
\end_layout

\begin_layout Plain Layout

irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
\end_layout

\begin_layout Plain Layout

p <- qplot(Petal.Width, Petal.Length, col=Species, data=training)
\end_layout

\begin_layout Plain Layout

p + geom_point(aes(x=Petal.Width,y=Petal.Length, col=Species), size=5, shape=4,
 data=irisP)
\end_layout

\begin_layout Plain Layout

## Predicting new values
\end_layout

\begin_layout Plain Layout

pred <- predict(modFit, testing); testing$predRight <- pred==testing$Species
\end_layout

\begin_layout Plain Layout

table(pred,testing$Species)
\end_layout

\begin_layout Plain Layout

qplot(Petal.Width, Petal.Length, color=predRight, data=testing, main="newdata
 Predictions")
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Random forests are usually one of the two top-performing algorithsm (along
 with boosting) in prediction contests.
\end_layout

\begin_layout Itemize
Random forests are difficult to interpret, but often very accurate.
\end_layout

\begin_layout Itemize
Care should be taken to avoid overfitting (see 
\family typewriter
rfcv
\family default
 function).
\end_layout

\begin_layout Subsection*
Boosting
\end_layout

\begin_layout Itemize
Basic idea:
\end_layout

\begin_deeper
\begin_layout Itemize
Take lots of (possibly) weak predictors.
\end_layout

\begin_layout Itemize
Weight them and add them up.
\end_layout

\begin_layout Itemize
Get a stronger predictor.
\end_layout

\end_deeper
\begin_layout Itemize
Overview:
\end_layout

\begin_deeper
\begin_layout Itemize
Start with a set of classifiers 
\begin_inset Formula $h_{1},...,h_{k}$
\end_inset

 (example: all possible trees, all possible regression models, etc.)
\end_layout

\begin_layout Itemize
Create a classifier that combines classification functions: 
\begin_inset Formula $f\left(x\right)=\text{sgn }\sum_{t=1}^{T}\alpha_{t}h_{t}\left(x\right)$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Goal is to minimize error on training set.
\end_layout

\begin_layout Itemize
Iterative, select one 
\begin_inset Formula $h$
\end_inset

 at each step.
\end_layout

\begin_layout Itemize
Calculate weights based on errors.
\end_layout

\begin_layout Itemize
Upweight missed classifications and select next 
\begin_inset Formula $h$
\end_inset

.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Boosting in R:
\end_layout

\begin_deeper
\begin_layout Itemize
Can be used with any subset of classifiers.
\end_layout

\begin_layout Itemize
One large subclass is gradient boosting.
\end_layout

\begin_layout Itemize
Multiple libraries in R: differences include the choice of basic classification
 functions and combination rules.
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
gbm
\family default
: boosting with trees.
\end_layout

\begin_layout Itemize

\family typewriter
mboost
\family default
: model-based boosting.
\end_layout

\begin_layout Itemize

\family typewriter
ada
\family default
: statistical boosting based on additive logistic regression.
\end_layout

\begin_layout Itemize

\family typewriter
gamBoost
\family default
: for boosting generalized additive models.
\end_layout

\end_deeper
\begin_layout Itemize
Most of these are available in the 
\family typewriter
caret
\family default
 package.
\end_layout

\end_deeper
\begin_layout Itemize
Example (wage data):
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(ISLR); data(Wage); library(ggplot2); library(caret);
\end_layout

\begin_layout Plain Layout

Wage <- subset(Wage, select=-c(logwage))
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=Wage$wage, p=.07, list=F)
\end_layout

\begin_layout Plain Layout

training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Fit the model.
\end_layout

\begin_layout Plain Layout

modFit <- train(wage ~ ., method="gbm", data=training, verbose=F)
\end_layout

\begin_layout Plain Layout

print(modFit)
\end_layout

\begin_layout Plain Layout

## Plot the results.
\end_layout

\begin_layout Plain Layout

qplot(predict(modFit,testing), wage, data=testing)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Model-based prediction
\end_layout

\begin_layout Itemize
Basic idea:
\end_layout

\begin_deeper
\begin_layout Itemize
Assume that the data follow a probabilistic model.
\end_layout

\begin_layout Itemize
Use Bayes' theorem to identify optimal classifiers.
\end_layout

\begin_layout Itemize
Pros: can take advantage of the structure of the data, may be computationally
 convenient, are reasonably accurate on real problems.
\end_layout

\begin_layout Itemize
Cons: make additional assumptions about the data, and when the model is
 incorrect, you may get reduced accuracy.
\end_layout

\end_deeper
\begin_layout Itemize
Model based approach:
\end_layout

\begin_deeper
\begin_layout Itemize
Goal is to build a parametric model for conditional distribution 
\begin_inset Formula $P\left(Y=k|X=x\right)$
\end_inset

 (probabily that our outcome 
\begin_inset Formula $Y$
\end_inset

 is in some class 
\begin_inset Formula $k$
\end_inset

 given our predictor variables 
\begin_inset Formula $X$
\end_inset

 in a class 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Itemize
A typical approach is to apply Bayes' theorem:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $P\left(Y=k|X=x\right)=\frac{P\left(X=x|Y=k\right)P\left(Y=k\right)}{\sum_{l=1}^{K}P\left(X=x|Y=l\right)P\left(Y=l\right)}$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $P\left(Y=k|X=x\right)=\frac{f_{k}\left(x\right)\pi_{k}}{\sum_{l=1}^{K}f_{l}\left(x\right)\pi_{l}}$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Typically, prior probabilities 
\begin_inset Formula $\pi_{k}$
\end_inset

 are set in advance.
\end_layout

\begin_layout Itemize
A common choice for 
\begin_inset Formula $f_{k}\left(x\right)$
\end_inset

 is a Gaussian distribution.
\end_layout

\begin_layout Itemize
Estimate the parameters 
\begin_inset Formula $\left(\mu_{k,}\sigma_{k}^{2}\right)$
\end_inset

 from the data.
\end_layout

\begin_layout Itemize
Classify to the class with the highest value of 
\begin_inset Formula $P\left(Y=k|X=x\right)$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
Classifying using the model: a range of models use this approach.
\end_layout

\begin_deeper
\begin_layout Itemize
Linear discriminant analysis assumes 
\begin_inset Formula $f_{k}\left(x\right)$
\end_inset

 is multivariate Gaussian with the same covariances.
\end_layout

\begin_deeper
\begin_layout Itemize
Discriminant function: 
\begin_inset Formula $\delta_{k}\left(x\right)=x^{T}\Sigma^{-1}\mu_{k}-\frac{1}{2}\mu_{k}\Sigma^{-1}\mu_{k}+\log\left(\mu_{k}\right)$
\end_inset


\end_layout

\begin_layout Itemize
Decide on class based on 
\begin_inset Formula $\hat{Y}\left(x\right)=\text{argmax }\left(x_{k},\delta_{k}\left(x\right)\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
We usually estimate parameters with maximum likelihood.
\end_layout

\end_deeper
\begin_layout Itemize
Quadratic discriminant analysis assumes 
\begin_inset Formula $f_{k}\left(x\right)$
\end_inset

 is multivariate Gaussian with different covariances.
\end_layout

\begin_layout Itemize
Model based prediction assumes more complicated versions for the covariance
 matrix.
\end_layout

\begin_layout Itemize
Naive Bayes assumes independence between features for model building.
\end_layout

\begin_deeper
\begin_layout Itemize
Suppose we have many predictors we would want to model 
\begin_inset Formula $P\left(Y=k|X_{1},...,X_{m}\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
We could use Bayes' theorem to get 
\begin_inset Formula $P\left(Y=k|X_{1},...,X_{m}\right)=\frac{\pi_{k}P\left(X_{1},...,X_{m}|Y=k\right)}{\sum_{l=1}^{K}P\left(X_{1},...,X_{m}|Y=k\right)\pi_{l}}\propto\pi_{k}P\left(X_{1},...,X_{m}|Y=k\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
This can be written as 
\begin_inset Formula $\pi_{k}P\left(X_{1}|Y=k\right)P\left(X_{2}|X_{1},Y=k\right)...P\left(X_{m}|X_{1},...,X_{m-1}|Y=k\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
We could make an assumption of independence to write: 
\begin_inset Formula $\approx\pi_{k}P\left(X_{1}|Y=k\right)P\left(X_{2}|Y=k\right)...P\left(X_{m}|Y=k\right)$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Itemize
This is not a great assumption always, hence the name 
\begin_inset Quotes eld
\end_inset

naive
\begin_inset Quotes erd
\end_inset

 Bayes.
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Itemize
Example: iris data
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

data(iris); library(ggplot2)
\end_layout

\begin_layout Plain Layout

names(iris)
\end_layout

\begin_layout Plain Layout

## Make training and testing sets
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=iris$Species, p=0.7, list=F)
\end_layout

\begin_layout Plain Layout

training <- iris[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- iris[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Build predictions with LDA and NB.
\end_layout

\begin_layout Plain Layout

modlda <- train(Species ~ ., data=trianing, method="lda")
\end_layout

\begin_layout Plain Layout

modnb <- train(Species ~ ., data=training, method="nb")
\end_layout

\begin_layout Plain Layout

plda <- predict(modlda, testing); pnb <- predict(modnb, testing)
\end_layout

\begin_layout Plain Layout

## Compare results
\end_layout

\begin_layout Plain Layout

table(plda,pnb)
\end_layout

\begin_layout Plain Layout

equalPredictions <- (plda == pnb)
\end_layout

\begin_layout Plain Layout

qplot(Petal.Width, Sepal.Width, color=equalPredictions, data=testing)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Regularized regression
\end_layout

\begin_layout Itemize
Basic idea: fit a regression model, then penalize or shrink large coefficients.
\end_layout

\begin_layout Itemize
Pros: can help with the bias/variance tradeoff and can help with model selection.
\end_layout

\begin_layout Itemize
Cons: may be computationally demanding, does not perform as well as random
 forests or boosting.
\end_layout

\begin_layout Itemize
A motivating example:
\end_layout

\begin_deeper
\begin_layout Itemize
Fit a regression example 
\begin_inset Formula $Y=\beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\epsilon$
\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 are nearly perfectly correlated (co-linear), you can approximate the model
 by 
\begin_inset Formula $Y=\beta_{0}+\left(\beta_{1}+\beta_{2}\right)X_{1}+\epsilon$
\end_inset

 .
\end_layout

\begin_layout Itemize
The result is:
\end_layout

\begin_deeper
\begin_layout Itemize
You will get a good estimate of 
\begin_inset Formula $Y$
\end_inset

.
\end_layout

\begin_layout Itemize
The estimate of 
\begin_inset Formula $Y$
\end_inset

 will be biased.
\end_layout

\begin_layout Itemize
We may reduce variance in the estimate.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
A common pattern is that training error will always go down as we add predictors.
 The testing error will go down to a certain point, but then it will start
 going back up, due to overfitting.
\end_layout

\begin_layout Itemize
Model selection approach: split samples
\end_layout

\begin_deeper
\begin_layout Itemize
No better method when data/computation time permits it.
\end_layout

\begin_layout Itemize
Approach:
\end_layout

\begin_deeper
\begin_layout Itemize
Divide data into training/test/validation.
\end_layout

\begin_layout Itemize
Treat validation as test data, train all competing models on the train data
 and pick the best one on validation.
\end_layout

\begin_layout Itemize
To appropriately assess performance on new data, apply it to the test set.
\end_layout

\begin_layout Itemize
You may re-spilt and re-perform steps 1-3.
\end_layout

\end_deeper
\begin_layout Itemize
Two common problems:
\end_layout

\begin_deeper
\begin_layout Itemize
Limited data, may not be able to do many subsets of data.
\end_layout

\begin_layout Itemize
Computational complexity.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Decomposing expected prediction error
\end_layout

\begin_deeper
\begin_layout Itemize
Assume 
\begin_inset Formula $Y_{i}=f\left(X_{i}\right)+\epsilon_{i}$
\end_inset


\end_layout

\begin_layout Itemize
Expected prediction error: 
\begin_inset Formula $EPE\left(\lambda\right)=E\left[\left\{ Y-\hat{f}_{\lambda}\left(X\right)\right\} ^{2}\right]$
\end_inset


\end_layout

\begin_layout Itemize
Suppose 
\begin_inset Formula $\hat{f}_{\lambda}$
\end_inset

 is the estimate from the training data and look at a new data point 
\begin_inset Formula $X=x^{\star}$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $E\left[\left\{ Y-\hat{f}_{\lambda}\left(x^{\star}\right)\right\} ^{2}\right]=\sigma^{2}+\left\{ E\left[\hat{f}_{\lambda}\left(x^{\star}\right)\right]-f\left(x^{\star}\right)\right\} ^{2}+Var\left[\hat{f}_{\lambda}\left(x_{0}\right)\right]=\text{Irreducible error + Bias}^{2}\text{ + Variance}$
\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Hard thresholding
\end_layout

\begin_deeper
\begin_layout Itemize
Model 
\begin_inset Formula $Y=f\left(X\right)+\epsilon$
\end_inset


\end_layout

\begin_layout Itemize
Set 
\begin_inset Formula $\hat{f}_{\lambda}\left(x\right)=x'\beta$
\end_inset

 
\end_layout

\begin_layout Itemize
Constrain only 
\begin_inset Formula $\lambda$
\end_inset

 coefficients to be nonzero.
\end_layout

\begin_layout Itemize
Selection problem is after choosing 
\begin_inset Formula $\lambda$
\end_inset

, figure out which 
\begin_inset Formula $p-\lambda$
\end_inset

 coefficients to make nonzero.
\end_layout

\end_deeper
\begin_layout Itemize
Regularization for regression
\end_layout

\begin_deeper
\begin_layout Itemize
If the 
\begin_inset Formula $\beta_{j}$
\end_inset

s are unconstrained, they can explode.
 Hence, they are susceptible to very high variance.
\end_layout

\begin_layout Itemize
To control variance, we might regularize/shrink the coefficients:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $PRSS\left(\beta\right)=\sum_{j=1}^{n}\left(Y_{j}-\sum_{i=1}^{m}B_{1i}X_{ij}\right)^{2}+P\left(\lambda;\beta\right)$
\end_inset

, where PRSS is a penalized form of the sum of squares.
\end_layout

\end_deeper
\begin_layout Itemize
Things that are commonly looked for:
\end_layout

\begin_deeper
\begin_layout Itemize
Penalty reduces complexity.
\end_layout

\begin_layout Itemize
Penalty reduces variance.
\end_layout

\begin_layout Itemize
Penalty respects structure of the problem.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Ridge regression
\end_layout

\begin_deeper
\begin_layout Itemize
Solve: 
\begin_inset Formula $\sum_{i=1}^{N}\left(y_{i}-\beta_{0}+\sum_{j=1}^{p}x_{ij}\beta_{j}\right)^{2}+\lambda\sum_{j=1}^{p}\beta_{j}^{2}$
\end_inset

.
\end_layout

\begin_layout Itemize
This is equivalent to solving 
\begin_inset Formula $\sum_{i=1}^{N}\left(y_{i}-\beta_{0}+\sum_{j=1}^{p}x_{ij}\beta_{j}\right)^{2}$
\end_inset

 subject to 
\begin_inset Formula $\sum_{j=1}^{p}\beta_{j}^{2}\leq s$
\end_inset

, where 
\begin_inset Formula $s$
\end_inset

 is inversely proportional to 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Itemize
Inclusion of 
\begin_inset Formula $\lambda$
\end_inset

 makes the problem non-singular even if 
\begin_inset Formula $X^{T}X$
\end_inset

 is not invertible.
\end_layout

\end_deeper
\begin_layout Itemize
Tuning parameter 
\begin_inset Formula $\lambda$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Controls the size of the coefficients.
\end_layout

\begin_layout Itemize
Controls the amount of regularization.
\end_layout

\begin_layout Itemize
As 
\begin_inset Formula $\lambda\rightarrow0$
\end_inset

, we obtain the least squares solution.
\end_layout

\begin_layout Itemize
As 
\begin_inset Formula $\lambda\rightarrow\infty$
\end_inset

, we have 
\begin_inset Formula $\hat{\beta}_{\lambda=\infty}^{ridge}=0$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
In 
\family typewriter
caret
\family default
 package, some methods for fitting penalized regression models are:
\end_layout

\begin_deeper
\begin_layout Itemize

\family typewriter
ridge
\end_layout

\begin_layout Itemize

\family typewriter
lasso
\end_layout

\begin_layout Itemize

\family typewriter
relaxo
\end_layout

\end_deeper
\begin_layout Subsection*
Combining predictors
\end_layout

\begin_layout Itemize
Also known as ensembling methods.
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Combine classifiers by averaging or voting.
 In general these can be very different classifiers.
\end_layout

\begin_layout Itemize
Combing classifers improves accuracy, but reduces interpretability.
\end_layout

\begin_layout Itemize
Boosting, bagging, and random forests are variants on this theme, but they
 all average the same kinds of classifiers.
\end_layout

\end_deeper
\begin_layout Itemize
Example: Netflix prize 
\begin_inset Quotes eld
\end_inset

BellKor
\begin_inset Quotes erd
\end_inset

 combined 107 predictors.
\end_layout

\begin_layout Itemize
Basic intuition - majority vote.
\end_layout

\begin_deeper
\begin_layout Itemize
If we have 5 completely independent classifiers, and the accuracy is 70%
 for each, 
\begin_inset Formula $10\times0.7^{3}\times0.3^{2}+5\times0.7^{4}\times0.3+0.7^{5}=0.837$
\end_inset

 majority vote accuracy.
\end_layout

\begin_layout Itemize
With 101 independent classifiers, we get 
\begin_inset Formula $0.999$
\end_inset

 majority vote accuracy.
\end_layout

\end_deeper
\begin_layout Itemize
Approaches for combining classifiers:
\end_layout

\begin_deeper
\begin_layout Itemize
Bagging, boosting, random forests - these all usually combine similar classifier
s.
\end_layout

\begin_layout Itemize
Combining different classifiers - model stacking and model ensembling.
\end_layout

\end_deeper
\begin_layout Itemize
Model stacking - example with Wage data.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(ISLR); data(Wage); library(ggplot2); library(caret);
\end_layout

\begin_layout Plain Layout

Wage <- subset(Wage, select=-c(logwage))
\end_layout

\begin_layout Plain Layout

## Create a building data set and a validation data set.
\end_layout

\begin_layout Plain Layout

inBuild <- createDataPartition(y=Wage$wage, p=0.7, list=F)
\end_layout

\begin_layout Plain Layout

validation <- Wage[-inBuild,]; buildData <- Wage[inBuild,]
\end_layout

\begin_layout Plain Layout

## Split build data into training and testing.
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=buildData$wage, p=0.7, list=F)
\end_layout

\begin_layout Plain Layout

training <- buildData[inTrain,]; testing <- buildData[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Build two different models with the training set.
\end_layout

\begin_layout Plain Layout

mod1 <- train(wage ~ ., method="glm", data=training)
\end_layout

\begin_layout Plain Layout

mod2 <- train(wage ~ ., method="rf", data=training, trControl = trainControl(meth
od="cv"), number=3)
\end_layout

\begin_layout Plain Layout

## Predict on the testing set.
\end_layout

\begin_layout Plain Layout

pred1 <- predict(mod1, testing); pred2 <- predict(mod2, testing)
\end_layout

\begin_layout Plain Layout

qplot(pred1,pred2,color=wage,data=testing)
\end_layout

\begin_layout Plain Layout

## Fit a model that combines predictors.
\end_layout

\begin_layout Plain Layout

predDF <- data.frame(pred1, pred2, wage=testing$wage)
\end_layout

\begin_layout Plain Layout

combModFit <- train(wage ~ ., method="gam", data=predDF)
\end_layout

\begin_layout Plain Layout

combPred <- predict(combModFit, predDF)
\end_layout

\begin_layout Plain Layout

## Testing errors.
\end_layout

\begin_layout Plain Layout

sqrt(sum((pred1-testing$wage)^2))
\end_layout

\begin_layout Plain Layout

sqrt(sum((pred2-testing$wage)^2))
\end_layout

\begin_layout Plain Layout

sqrt(sum((combPred-testing$wage)^2))
\end_layout

\begin_layout Plain Layout

## Predict on validation data set.
\end_layout

\begin_layout Plain Layout

pred1V <- predict(mod1, validation); pred2V <- predict(mod2, validation)
\end_layout

\begin_layout Plain Layout

predVDF <- data.frame(pred1=pred1V, pred2=pred2V)
\end_layout

\begin_layout Plain Layout

combPredV <- predict(combModFit, predVDF)
\end_layout

\begin_layout Plain Layout

## Evaluate on validation.
\end_layout

\begin_layout Plain Layout

sqrt(sum((pred1V-validation$wage)^2))
\end_layout

\begin_layout Plain Layout

sqrt(sum((pred2V-validation$wage)^2))
\end_layout

\begin_layout Plain Layout

sqrt(sum((combPredV-validation$wage)^2))
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Even simple blending can be useful to improve accuracy.
\end_layout

\begin_layout Itemize
Typical model for binary/multiclass data.
\end_layout

\begin_deeper
\begin_layout Itemize
Build an odd number of models.
\end_layout

\begin_layout Itemize
Predict with each model.
\end_layout

\begin_layout Itemize
Predict the class by majority vote.
\end_layout

\end_deeper
\begin_layout Itemize
This can get much more complicated:
\end_layout

\begin_deeper
\begin_layout Itemize
Simple blending in caret: 
\family typewriter
caretEnsemble
\family default
 (use at your own risk).
\end_layout

\end_deeper
\begin_layout Itemize
Recall: scalability matters! This can be very computationally complex, hard
 to scale up to large data sets.
\end_layout

\begin_layout Subsection*
Forecasting
\end_layout

\begin_layout Itemize
Forecasting is a type of prediction problem that applies to time-series
 data (stocks, for example).
\end_layout

\begin_layout Itemize
What is different?
\end_layout

\begin_deeper
\begin_layout Itemize
Data are time-dependent.
\end_layout

\begin_layout Itemize
Specific pattern types:
\end_layout

\begin_deeper
\begin_layout Itemize
Trends - long-term increase or decrease.
\end_layout

\begin_layout Itemize
Seasonal patterns - related to time of week, month, year, etc.
 There is a pattern which recurs over a fixed period of time.
\end_layout

\begin_layout Itemize
Cycles - patterns that rise and fall periodically over non-fixed periods
 of time.
\end_layout

\end_deeper
\begin_layout Itemize
Subsampling into training/test sets is more complicated.
\end_layout

\begin_layout Itemize
Similar issues arise in spatial data:
\end_layout

\begin_deeper
\begin_layout Itemize
Dependency between nearby observations.
\end_layout

\begin_layout Itemize
Location-specific effects.
\end_layout

\end_deeper
\begin_layout Itemize
Typically, the goal is to predict one or more observations into the future.
\end_layout

\begin_layout Itemize
All standard predictions can be used (with caution)!
\end_layout

\end_deeper
\begin_layout Itemize
Also common in geographic analyses.
\end_layout

\begin_layout Itemize
Beware extrapolation!
\end_layout

\begin_layout Itemize
Useful for forecasting: simple moving average.
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $Y_{t}=\frac{1}{2k+1}\sum_{j=-k}^{k}y_{t+j}$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Also useful: exponential smoothing - weighting nearby points in time more
 heavily than those which are farther away.
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\hat{y}_{t+1}=\alpha y_{t}+\left(1-\alpha\right)\hat{y}_{t-1}$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Example: Google data
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

library(quantmod)
\end_layout

\begin_layout Plain Layout

from.dat <- as.Date("01/01/08", format"%m/%d/%y")
\end_layout

\begin_layout Plain Layout

to.dat <- as.Date("12/31/13", format="%m/%d/%y")
\end_layout

\begin_layout Plain Layout

getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
\end_layout

\begin_layout Plain Layout

## Get monthly summary and store as a time-series.
\end_layout

\begin_layout Plain Layout

mGoog <- to.monthly(GOOG)
\end_layout

\begin_layout Plain Layout

googOpen <- Op(mGoog)
\end_layout

\begin_layout Plain Layout

ts1 <- ts(googOpen, frequency=12)
\end_layout

\begin_layout Plain Layout

plot(ts1, xlab="Years+1", ylab="GOOG")
\end_layout

\begin_layout Plain Layout

## Decompose a time-series into parts (trends, patterns, cycles).
\end_layout

\begin_layout Plain Layout

plot(decompose(ts1), xlab="Years+1")
\end_layout

\begin_layout Plain Layout

## Training and test sets.
\end_layout

\begin_layout Plain Layout

ts1Train <- window(ts1, start=1, end=5)
\end_layout

\begin_layout Plain Layout

ts1Test <- window(ts1, start=5, end=(7-0.01))
\end_layout

\begin_layout Plain Layout

## Simple moving average.
\end_layout

\begin_layout Plain Layout

plot(tst1Train)
\end_layout

\begin_layout Plain Layout

lines(ma(ts1Train, order=3), col="red")
\end_layout

\begin_layout Plain Layout

## Exponential smoothing.
\end_layout

\begin_layout Plain Layout

ets1 <- ets(ts1Train, model="MMM")
\end_layout

\begin_layout Plain Layout

fcast <- forecast(ets1)
\end_layout

\begin_layout Plain Layout

plot(fcast); lines(ts1Test, col="red")
\end_layout

\begin_layout Plain Layout

## Get the accuracy.
\end_layout

\begin_layout Plain Layout

accuracy(fcast, ts1Test)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Forecasting and time-series prediction is an entire field.
\end_layout

\begin_layout Itemize
Rob Hyndman's 
\begin_inset Quotes eld
\end_inset

Forecasting: principles and practice
\begin_inset Quotes erd
\end_inset

 is a good place to start.
 (free online book)
\end_layout

\begin_layout Itemize
Cautions:
\end_layout

\begin_deeper
\begin_layout Itemize
Be wary of spurious correlations.
\end_layout

\begin_layout Itemize
Be careful about how far you predict into the future.
\end_layout

\begin_layout Itemize
Be wary of dependencies over time.
\end_layout

\end_deeper
\begin_layout Itemize
See the 
\family typewriter
quantmod
\family default
 or 
\family typewriter
quandl
\family default
 packages for finance-related problems.
\end_layout

\begin_layout Subsection*
Unsupervised prediction
\end_layout

\begin_layout Itemize
Key ideas:
\end_layout

\begin_deeper
\begin_layout Itemize
Sometimes you don't know the labels for prediction.
\end_layout

\begin_layout Itemize
To build a predictor:
\end_layout

\begin_deeper
\begin_layout Itemize
Create clusters that you're observed (not always obvious).
\end_layout

\begin_layout Itemize
Add names to the clusters (i.e., how to interpret the clusters).
\end_layout

\begin_layout Itemize
Build a predictor for clusters.
\end_layout

\end_deeper
\begin_layout Itemize
In a new dataset, predict clusters.
\end_layout

\end_deeper
\begin_layout Itemize
Example: iris data ignoring species clusters.
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

data(iris); library(ggplot2)
\end_layout

\begin_layout Plain Layout

inTrain <- createDataPartition(y=iris#Species, p=0.7, list=F)
\end_layout

\begin_layout Plain Layout

training <- iris[inTrain,]
\end_layout

\begin_layout Plain Layout

testing <- iris[-inTrain,]
\end_layout

\begin_layout Plain Layout

## Clustering with k-means
\end_layout

\begin_layout Plain Layout

kMeans1 <- kmeans(subset(training, select=-c(Species)), centers=3)
\end_layout

\begin_layout Plain Layout

training$clusters <- as.factor(kMeans1$cluster)
\end_layout

\begin_layout Plain Layout

qplot(Petal.Width, Petal.Length, color=clusters, data=training)
\end_layout

\begin_layout Plain Layout

## Compare to real labels.
\end_layout

\begin_layout Plain Layout

table(kMean1$cluster, training$Species)
\end_layout

\begin_layout Plain Layout

## Build a predictor.
\end_layout

\begin_layout Plain Layout

modFit <- train(clusters ~ ., data=subset(training, select=-c(Species)),
 method="rpart")
\end_layout

\begin_layout Plain Layout

table(predict(modFit,training), training$Species)
\end_layout

\begin_layout Plain Layout

## Apply to test dataset.
\end_layout

\begin_layout Plain Layout

testClusterPred <- predict(modFit, testing)
\end_layout

\begin_layout Plain Layout

table(testClusterPred, testing$Species)
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Notes:
\end_layout

\begin_deeper
\begin_layout Itemize
The 
\family typewriter
cl_predict
\family default
 function in the 
\family typewriter
clue
\family default
 package provides similar functionality.
\end_layout

\begin_layout Itemize
Beware over-interpretation of clusters!
\end_layout

\begin_layout Itemize
This is one basic approach to recommendation engines.
\end_layout

\end_deeper
\end_body
\end_document

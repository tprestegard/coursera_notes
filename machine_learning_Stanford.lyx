#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Machine Learning (Stanford)
\end_layout

\begin_layout Author
Tanner Prestegard
\end_layout

\begin_layout Date
Course taken from 10/5/2015 - 12/27/2015
\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Subsection*
Supervised learning
\end_layout

\begin_layout Itemize
Say you have data which gives the price and square footage of several houses.
\end_layout

\begin_layout Itemize
You want to predict the price given some square footage as an input.
\end_layout

\begin_layout Itemize
You can fit any type of function to the data: linear, quadratic, etc.
\end_layout

\begin_layout Itemize
Supervised learning: using a dataset where the 
\begin_inset Quotes eld
\end_inset

right
\begin_inset Quotes erd
\end_inset

 answers are known.
\end_layout

\begin_layout Itemize
Regression problem: predict a continuous valued output.
\end_layout

\begin_layout Itemize
Classification problem: predict for a problem with a discrete output.
\end_layout

\begin_deeper
\begin_layout Itemize
Also want to estimate the probability associated with the prediction.
\end_layout

\end_deeper
\begin_layout Itemize
Most interesting machine learning algorithms can deal with an infinite number
 of features!
\end_layout

\begin_deeper
\begin_layout Itemize
Requires a support vector machine - we will talk about this later in the
 course.
\end_layout

\end_deeper
\begin_layout Subsection*
Unsupervised learning
\end_layout

\begin_layout Itemize
We are given data where we don't know the 
\begin_inset Quotes eld
\end_inset

right answer.
\begin_inset Quotes erd
\end_inset

 The actual data is not classified as true or false.
\end_layout

\begin_layout Itemize
The question is: here is the dataset, can you find some structure in the
 data?
\end_layout

\begin_layout Itemize
Example: clustering algorithm.
 Used in Google news to group similar stories together.
\end_layout

\begin_deeper
\begin_layout Itemize
In this method, the algorithm assigns group labels to different clusters.
\end_layout

\end_deeper
\begin_layout Itemize
Other examples: social network analysis, organization of computer clusters,
 market segmentation, astronomical data analysis.
\end_layout

\begin_layout Itemize
Example: cocktail party problem - useful for separating highly correlated
 audio tracks into independent tracks.
\end_layout

\begin_deeper
\begin_layout Itemize
Cocktail party problem algorithm: 
\family typewriter
[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x');
\family default
 (singular value decomposition)
\end_layout

\end_deeper
\begin_layout Section*
Linear regression with one variable
\end_layout

\begin_layout Subsection*
Model and cost function
\end_layout

\begin_layout Itemize
Regression problem: predict a (continuous output).
\end_layout

\begin_layout Itemize
General notation for this course:
\end_layout

\begin_deeper
\begin_layout Itemize

\emph on
m
\emph default
: number of examples in the training dataset.
\end_layout

\begin_layout Itemize

\emph on
x
\emph default
: input variables/features.
\end_layout

\begin_layout Itemize

\emph on
y
\emph default
: output variable/target.
\end_layout

\begin_layout Itemize

\emph on
(x,y)
\emph default
: denotes a single training example.
\end_layout

\end_deeper
\begin_layout Itemize
General flow:
\end_layout

\begin_deeper
\begin_layout Itemize
Training set -> learning algorithm -> hypothesis function.
\end_layout

\begin_layout Itemize
The hypothesis function takes input (
\emph on
x
\emph default
) and predicts the outcome (
\emph on
y
\emph default
).
 It maps from 
\emph on
x
\emph default
's to 
\emph on
y
\emph default
's.
\end_layout

\end_deeper
\begin_layout Itemize
How do we represent the hypothesis 
\emph on
h
\emph default
?
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $h_{\theta}\left(x\right)=\theta_{0}+\theta_{1}x$
\end_inset

 for univariate linear regression, or linear regression with one variable.
\end_layout

\begin_layout Itemize
The 
\begin_inset Formula $\theta$
\end_inset

's are the parameters of the model.
\end_layout

\end_deeper
\begin_layout Itemize
How do we choose the parameters of the model?
\end_layout

\begin_deeper
\begin_layout Itemize
Find 
\begin_inset Formula $\theta_{0}$
\end_inset

 and 
\begin_inset Formula $\theta_{1}$
\end_inset

 such that we minimize the sum of the squared errors: 
\begin_inset Formula $\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)^{2}$
\end_inset

.
\end_layout

\begin_layout Itemize
Factor of 
\begin_inset Formula $\frac{1}{2m}$
\end_inset

 doesn't affect parameter values and will make later math a bit easier.
\end_layout

\begin_layout Itemize
This also defined as the cost function 
\begin_inset Formula $J\left(\theta_{0},\theta_{1}\right)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}\left(x^{\left(i\right)}\right)-y^{\left(i\right)}\right)^{2}$
\end_inset

.
\end_layout

\begin_deeper
\begin_layout Itemize
There are other cost functions that may work as well, but the squared error
 cost function is the most commonly used one for linear regression.
\end_layout

\end_deeper
\begin_layout Itemize
Can be useful to plot cost function in terms of the parameters 
\begin_inset Formula $\theta_{0}$
\end_inset

 and 
\begin_inset Formula $\theta_{1}$
\end_inset

.
\end_layout

\end_deeper
\end_body
\end_document
